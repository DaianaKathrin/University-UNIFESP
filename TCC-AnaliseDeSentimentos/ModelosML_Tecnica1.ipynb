{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d977afc7",
   "metadata": {},
   "source": [
    "# Importando bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e57baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e77bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro_train = pd.read_excel('Bolsonaro_treino_sem_stop.xlsx')  \n",
    "df_lula_train = pd.read_excel('Lula_treino_sem_stop.xlsx') \n",
    "df_simone_train = pd.read_excel('Simone_treino_sem_stop.xlsx') \n",
    "df_ciro_train = pd.read_excel('Ciro_treino_sem_stop.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f914181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro = pd.read_excel('Bolsonaro_todos_sem_stop.xlsx', index_col=0)\n",
    "df_lula = pd.read_excel('Lula_todos_sem_stop.xlsx', index_col=0)\n",
    "df_simone = pd.read_excel('Simone_todos_sem_stop.xlsx', index_col=0)\n",
    "df_ciro = pd.read_excel('Ciro_todos_sem_stop.xlsx', index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e2f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lula_train = df_lula_train[df_lula_train['Sentimento']!=' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18fc2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag Of Words\n",
    "\n",
    "def Bag_of_words(df):\n",
    "    matrix = CountVectorizer()\n",
    "    text = []\n",
    "    for i in df.index:\n",
    "        text.append(\"\".join(df['novo_texto'][i]))\n",
    "    X = matrix.fit_transform(text)\n",
    "    return X, matrix\n",
    "\n",
    "def Bag_of_words_teste(df, matrix):\n",
    "    text = []\n",
    "    for i in df.index:\n",
    "        text.append(\"\".join(df['novo_texto'][i]))\n",
    "    X = matrix.transform(text)\n",
    "    return X\n",
    "\n",
    "def tfidf(df):\n",
    "    matrix = TfidfVectorizer()\n",
    "    text = []\n",
    "    for i in df.index:\n",
    "        text.append(\"\".join(df['novo_texto'][i]))\n",
    "    X = matrix.fit_transform(text)\n",
    "    return X, matrix\n",
    "\n",
    "def tfidf_teste(df, matrix):\n",
    "    text = []\n",
    "    for i in df.index:\n",
    "        text.append(\"\".join(df['novo_texto'][i]))\n",
    "    X = matrix.transform(text)\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464bd3fa",
   "metadata": {},
   "source": [
    "## Base treino bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab177c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bw_bolsonaro_train, bw_bolsonaro = Bag_of_words(df_bolsonaro_train)\n",
    "X_bw_lula_train, bw_lula = Bag_of_words(df_lula_train)\n",
    "X_bw_simone_train, bw_simone = Bag_of_words(df_simone_train)\n",
    "X_bw_ciro_train, bw_ciro = Bag_of_words(df_ciro_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f153217",
   "metadata": {},
   "source": [
    "## Base treino tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e295598",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_bolsonaro_train, tfidf_bolsonaro = tfidf(df_bolsonaro_train)\n",
    "X_tfidf_lula_train, tfidf_lula = tfidf(df_lula_train)\n",
    "X_tfidf_simone_train, tfidf_simone = tfidf(df_simone_train)\n",
    "X_tfidf_ciro_train, tfidf_ciro = tfidf(df_ciro_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da93a6ad",
   "metadata": {},
   "source": [
    "# Predict treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e810e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_bolsonaro_train = df_bolsonaro_train['Sentimento'].str.replace('p','1').replace('x','0').replace('n','-1').astype(int)\n",
    "Y_lula_train = df_lula_train['Sentimento'].str.replace('p','1').replace('x','0').replace('n','-1').astype(int)\n",
    "Y_simone_train = df_simone_train['Sentimento'].str.replace('p','1').replace('x','0').replace('n','-1').astype(int)\n",
    "Y_ciro_train = df_ciro_train['Sentimento'].str.replace('p','1').replace('x','0').replace('n','-1').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72038a02",
   "metadata": {},
   "source": [
    "## Bolsonaro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3ce554",
   "metadata": {},
   "source": [
    "### Bolsonaro - Arvore de Decisao - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2915f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([150453,   8193, 787792], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_bolsonaro_bw = tree.DecisionTreeClassifier()\n",
    "tree_bolsonaro_bw = tree_bolsonaro_bw.fit(X_bw_bolsonaro_train, Y_bolsonaro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_bw_tree = tree_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_bw_tree = np.append(predict_bolsonaro_bw_tree, tree_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_bw_tree = np.append(predict_bolsonaro_bw_tree,tree_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:], bw_bolsonaro).toarray()))\n",
    "\n",
    "\n",
    "df_bolsonaro['predict_bw_ArvoreDeDecisao'] = predict_bolsonaro_bw_tree\n",
    "\n",
    "np.unique(predict_bolsonaro_bw_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c00ac26",
   "metadata": {},
   "source": [
    "### Bolsonaro - Arvore de Decisao - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f7dd211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([159695,   8465, 778278], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_bolsonaro_tfidf = tree.DecisionTreeClassifier()\n",
    "tree_bolsonaro_tfidf = tree_bolsonaro_tfidf.fit(X_tfidf_bolsonaro_train, Y_bolsonaro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_tfidf_tree = tree_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_tfidf_tree = np.append(predict_bolsonaro_tfidf_tree, tree_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_tfidf_tree = np.append(predict_bolsonaro_tfidf_tree,tree_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:], tfidf_bolsonaro).toarray()))\n",
    "\n",
    "\n",
    "df_bolsonaro['predict_tfidf_ArvoreDeDecisao'] = predict_bolsonaro_tfidf_tree\n",
    "\n",
    "np.unique(predict_bolsonaro_tfidf_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f20d1b9",
   "metadata": {},
   "source": [
    "### Bolsonaro - Naive Bayes - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "397899ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([337731,  17663, 591044], dtype=int64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_bolsonaro_bw = GaussianNB()\n",
    "GaussianNB_bolsonaro_bw = GaussianNB_bolsonaro_bw.fit(X_bw_bolsonaro_train.toarray(), Y_bolsonaro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_bw_nb = GaussianNB_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_bw_nb = np.append(predict_bolsonaro_bw_nb, GaussianNB_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_bw_nb = np.append(predict_bolsonaro_bw_nb,GaussianNB_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:], bw_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_bw_NaiveBayes'] = predict_bolsonaro_bw_nb\n",
    "\n",
    "np.unique(predict_bolsonaro_bw_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372a05b",
   "metadata": {},
   "source": [
    "### Bolsonaro - Naive Bayes - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14a58562",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([336837,  17812, 591789], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_bolsonaro_tfidf = GaussianNB()\n",
    "GaussianNB_bolsonaro_tfidf = GaussianNB_bolsonaro_tfidf.fit(X_tfidf_bolsonaro_train.toarray(), Y_bolsonaro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_tfidf_nb = GaussianNB_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_tfidf_nb = np.append(predict_bolsonaro_tfidf_nb, GaussianNB_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_tfidf_nb = np.append(predict_bolsonaro_tfidf_nb,GaussianNB_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:], tfidf_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_tfidf_NaiveBayes'] = predict_bolsonaro_tfidf_nb\n",
    "\n",
    "np.unique(predict_bolsonaro_tfidf_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34759309",
   "metadata": {},
   "source": [
    "### Bolsonaro - Random Forest - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19a632ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 35177,   2794, 908467], dtype=int64))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_bolsonaro_bw = RandomForestClassifier()\n",
    "RandomForest_bolsonaro_bw = RandomForest_bolsonaro_bw.fit(X_bw_bolsonaro_train.toarray(), Y_bolsonaro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_bw_rf = RandomForest_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_bw_rf = np.append(predict_bolsonaro_bw_rf, RandomForest_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_bw_rf = np.append(predict_bolsonaro_bw_rf,RandomForest_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:], bw_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_bw_RandomForest'] = predict_bolsonaro_bw_rf\n",
    "\n",
    "np.unique(predict_bolsonaro_bw_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff29950",
   "metadata": {},
   "source": [
    "### Bolsonaro - Random Forest - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14f319cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 17225,   3903, 925310], dtype=int64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_bolsonaro_tfidf = RandomForestClassifier()\n",
    "RandomForest_bolsonaro_tfidf = RandomForest_bolsonaro_tfidf.fit(X_tfidf_bolsonaro_train.toarray(), Y_bolsonaro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_tfidf_rf = RandomForest_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_tfidf_rf = np.append(predict_bolsonaro_tfidf_rf, RandomForest_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_tfidf_rf = np.append(predict_bolsonaro_tfidf_rf,RandomForest_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:], tfidf_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_tfidf_RandomForest'] = predict_bolsonaro_tfidf_rf\n",
    "\n",
    "np.unique(predict_bolsonaro_tfidf_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf60d9",
   "metadata": {},
   "source": [
    "### Bolsonaro - SVM - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "046fb722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([130759,   4211, 811468], dtype=int64))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_bolsonaro_bw = LinearSVC()\n",
    "svc_bolsonaro_bw = svc_bolsonaro_bw.fit(X_bw_bolsonaro_train.toarray(), Y_bolsonaro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_bw_svc = svc_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_bw_svc = np.append(predict_bolsonaro_bw_svc, svc_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_bw_svc = np.append(predict_bolsonaro_bw_svc,svc_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:], bw_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_bw_svc'] = predict_bolsonaro_bw_svc\n",
    "\n",
    "np.unique(predict_bolsonaro_bw_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ecded",
   "metadata": {},
   "source": [
    "### Bolsonaro - SVM - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e941c453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 47202,     92, 899144], dtype=int64))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_bolsonaro_tfidf = LinearSVC()\n",
    "svc_bolsonaro_tfidf = svc_bolsonaro_tfidf.fit(X_tfidf_bolsonaro_train.toarray(), Y_bolsonaro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_tfidf_svc = svc_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_tfidf_svc = np.append(predict_bolsonaro_tfidf_svc, svc_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_tfidf_svc = np.append(predict_bolsonaro_tfidf_svc,svc_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:], tfidf_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_tfidf_svc'] = predict_bolsonaro_tfidf_svc\n",
    "\n",
    "np.unique(predict_bolsonaro_tfidf_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc02ed7",
   "metadata": {},
   "source": [
    "### Bolsonaro - MLP - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe667137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.77253503\n",
      "Iteration 2, loss = 0.48574396\n",
      "Iteration 3, loss = 0.37868152\n",
      "Iteration 4, loss = 0.29864111\n",
      "Iteration 5, loss = 0.23645597\n",
      "Iteration 6, loss = 0.18909241\n",
      "Iteration 7, loss = 0.15265182\n",
      "Iteration 8, loss = 0.12468498\n",
      "Iteration 9, loss = 0.10215033\n",
      "Iteration 10, loss = 0.08444633\n",
      "Iteration 11, loss = 0.07039765\n",
      "Iteration 12, loss = 0.05895100\n",
      "Iteration 13, loss = 0.05012049\n",
      "Iteration 14, loss = 0.04277194\n",
      "Iteration 15, loss = 0.03699673\n",
      "Iteration 16, loss = 0.03191597\n",
      "Iteration 17, loss = 0.02803580\n",
      "Iteration 18, loss = 0.02483467\n",
      "Iteration 19, loss = 0.02206917\n",
      "Iteration 20, loss = 0.01996539\n",
      "Iteration 21, loss = 0.01784546\n",
      "Iteration 22, loss = 0.01619280\n",
      "Iteration 23, loss = 0.01487629\n",
      "Iteration 24, loss = 0.01367443\n",
      "Iteration 25, loss = 0.01269454\n",
      "Iteration 26, loss = 0.01175903\n",
      "Iteration 27, loss = 0.01090482\n",
      "Iteration 28, loss = 0.01012915\n",
      "Iteration 29, loss = 0.00952184\n",
      "Iteration 30, loss = 0.00911158\n",
      "Iteration 31, loss = 0.00861956\n",
      "Iteration 32, loss = 0.00806041\n",
      "Iteration 33, loss = 0.00775925\n",
      "Iteration 34, loss = 0.00745306\n",
      "Iteration 35, loss = 0.00732885\n",
      "Iteration 36, loss = 0.00692426\n",
      "Iteration 37, loss = 0.00662820\n",
      "Iteration 38, loss = 0.00637052\n",
      "Iteration 39, loss = 0.00634217\n",
      "Iteration 40, loss = 0.00619795\n",
      "Iteration 41, loss = 0.00578580\n",
      "Iteration 42, loss = 0.00584110\n",
      "Iteration 43, loss = 0.00556696\n",
      "Iteration 44, loss = 0.00537668\n",
      "Iteration 45, loss = 0.00533417\n",
      "Iteration 46, loss = 0.00513097\n",
      "Iteration 47, loss = 0.00505598\n",
      "Iteration 48, loss = 0.00501502\n",
      "Iteration 49, loss = 0.00484451\n",
      "Iteration 50, loss = 0.00474312\n",
      "Iteration 51, loss = 0.00470463\n",
      "Iteration 52, loss = 0.00457901\n",
      "Iteration 53, loss = 0.00463337\n",
      "Iteration 54, loss = 0.00460953\n",
      "Iteration 55, loss = 0.00450068\n",
      "Iteration 56, loss = 0.00441745\n",
      "Iteration 57, loss = 0.00433881\n",
      "Iteration 58, loss = 0.00428657\n",
      "Iteration 59, loss = 0.00423787\n",
      "Iteration 60, loss = 0.00404233\n",
      "Iteration 61, loss = 0.00408064\n",
      "Iteration 62, loss = 0.00409096\n",
      "Iteration 63, loss = 0.00401896\n",
      "Iteration 64, loss = 0.00397631\n",
      "Iteration 65, loss = 0.00394089\n",
      "Iteration 66, loss = 0.00398466\n",
      "Iteration 67, loss = 0.00401239\n",
      "Iteration 68, loss = 0.00378183\n",
      "Iteration 69, loss = 0.00388269\n",
      "Iteration 70, loss = 0.00377242\n",
      "Iteration 71, loss = 0.00381746\n",
      "Iteration 72, loss = 0.00372505\n",
      "Iteration 73, loss = 0.00370969\n",
      "Iteration 74, loss = 0.00373352\n",
      "Iteration 75, loss = 0.00359661\n",
      "Iteration 76, loss = 0.00358445\n",
      "Iteration 77, loss = 0.00360195\n",
      "Iteration 78, loss = 0.00367719\n",
      "Iteration 79, loss = 0.00357734\n",
      "Iteration 80, loss = 0.00340047\n",
      "Iteration 81, loss = 0.00356668\n",
      "Iteration 82, loss = 0.00348936\n",
      "Iteration 83, loss = 0.00364863\n",
      "Iteration 84, loss = 0.00335717\n",
      "Iteration 85, loss = 0.00344079\n",
      "Iteration 86, loss = 0.00339801\n",
      "Iteration 87, loss = 0.00341662\n",
      "Iteration 88, loss = 0.00332926\n",
      "Iteration 89, loss = 0.00338509\n",
      "Iteration 90, loss = 0.00329584\n",
      "Iteration 91, loss = 0.00342586\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([158527,   4806, 783105], dtype=int64))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bolsonaro_bw = MLPClassifier()\n",
    "mlp_bolsonaro_bw = mlp_bolsonaro_bw.fit(X_bw_bolsonaro_train.toarray(), Y_bolsonaro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_bw_mlp = mlp_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_bw_mlp = np.append(predict_bolsonaro_bw_mlp, mlp_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_bw_mlp = np.append(predict_bolsonaro_bw_mlp,mlp_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:], bw_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_bw_mlp'] = predict_bolsonaro_bw_mlp\n",
    "df_bolsonaro['predict_bw_mlp2'] = predict_bolsonaro_bw_mlp\n",
    "\n",
    "np.unique(predict_bolsonaro_bw_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5742e772",
   "metadata": {},
   "source": [
    "### Bolsonaro - MLP - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "520c9697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([152195,   3494, 790749], dtype=int64))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bolsonaro_tfidf = MLPClassifier()\n",
    "mlp_bolsonaro_tfidf = mlp_bolsonaro_tfidf.fit(X_tfidf_bolsonaro_train.toarray(), Y_bolsonaro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_tfidf_mlp = mlp_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_tfidf_mlp = np.append(predict_bolsonaro_tfidf_mlp, mlp_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_tfidf_mlp = np.append(predict_bolsonaro_tfidf_mlp,mlp_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:], tfidf_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_tfidf_mlp'] = predict_bolsonaro_tfidf_mlp\n",
    "df_bolsonaro['predict_tfidf_mlp2'] = predict_bolsonaro_tfidf_mlp\n",
    "\n",
    "np.unique(predict_bolsonaro_tfidf_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a34601",
   "metadata": {},
   "source": [
    "# Lula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a24e8",
   "metadata": {},
   "source": [
    "### Lula - Arvore de Decisao - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f515b4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 86569,   1381, 843780], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_lula_bw = tree.DecisionTreeClassifier()\n",
    "tree_lula_bw = tree_lula_bw.fit(X_bw_lula_train, Y_lula_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_bw_tree = tree_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_bw_tree = np.append(predict_lula_bw_tree, tree_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_bw_tree = np.append(predict_lula_bw_tree,tree_lula_bw.predict(Bag_of_words_teste(df_lula[i1:], bw_lula).toarray()))\n",
    "\n",
    "\n",
    "df_lula['predict_bw_ArvoreDeDecisao'] = predict_lula_bw_tree\n",
    "\n",
    "np.unique(predict_lula_bw_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39748f6",
   "metadata": {},
   "source": [
    "### Lula - Arvore de Decisao - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7660abc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([146493,    989, 784248], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_lula_tfidf = tree.DecisionTreeClassifier()\n",
    "tree_lula_tfidf = tree_lula_tfidf.fit(X_tfidf_lula_train, Y_lula_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_tfidf_tree = tree_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_tfidf_tree = np.append(predict_lula_tfidf_tree, tree_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_tfidf_tree = np.append(predict_lula_tfidf_tree,tree_lula_tfidf.predict(tfidf_teste(df_lula[i1:], tfidf_lula).toarray()))\n",
    "\n",
    "\n",
    "df_lula['predict_tfidf_ArvoreDeDecisao'] = predict_lula_tfidf_tree\n",
    "\n",
    "np.unique(predict_lula_tfidf_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b35e18a",
   "metadata": {},
   "source": [
    "### Lula - Naive Bayes - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1363090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([404172,   7081, 520477], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_lula_bw = GaussianNB()\n",
    "GaussianNB_lula_bw = GaussianNB_lula_bw.fit(X_bw_lula_train.toarray(), Y_lula_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_bw_nb = GaussianNB_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_bw_nb = np.append(predict_lula_bw_nb, GaussianNB_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_bw_nb = np.append(predict_lula_bw_nb,GaussianNB_lula_bw.predict(Bag_of_words_teste(df_lula[i1:], bw_lula).toarray()))\n",
    "\n",
    "df_lula['predict_bw_NaiveBayes'] = predict_lula_bw_nb\n",
    "\n",
    "np.unique(predict_lula_bw_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c3903b",
   "metadata": {},
   "source": [
    "### Lula - Naive Bayes - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87f5b177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([402035,   7089, 522606], dtype=int64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_lula_tfidf = GaussianNB()\n",
    "GaussianNB_lula_tfidf = GaussianNB_lula_tfidf.fit(X_tfidf_lula_train.toarray(), Y_lula_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_tfidf_nb = GaussianNB_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_tfidf_nb = np.append(predict_lula_tfidf_nb, GaussianNB_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_tfidf_nb = np.append(predict_lula_tfidf_nb,GaussianNB_lula_tfidf.predict(tfidf_teste(df_lula[i1:], tfidf_lula).toarray()))\n",
    "\n",
    "df_lula['predict_tfidf_NaiveBayes'] = predict_lula_tfidf_nb\n",
    "\n",
    "np.unique(predict_lula_tfidf_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ae516",
   "metadata": {},
   "source": [
    "### Lula - Random Forest - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16862f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 20454,     30, 911246], dtype=int64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_lula_bw = RandomForestClassifier()\n",
    "RandomForest_lula_bw = RandomForest_lula_bw.fit(X_bw_lula_train.toarray(), Y_lula_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_bw_rf = RandomForest_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_bw_rf = np.append(predict_lula_bw_rf, RandomForest_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_bw_rf = np.append(predict_lula_bw_rf,RandomForest_lula_bw.predict(Bag_of_words_teste(df_lula[i1:], bw_lula).toarray()))\n",
    "\n",
    "df_lula['predict_bw_RandomForest'] = predict_lula_bw_rf\n",
    "\n",
    "np.unique(predict_lula_bw_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8821f0e",
   "metadata": {},
   "source": [
    "### Lula - Random Forest - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8035f9fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 18367,     28, 913335], dtype=int64))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_lula_tfidf = RandomForestClassifier()\n",
    "RandomForest_lula_tfidf = RandomForest_lula_tfidf.fit(X_tfidf_lula_train.toarray(), Y_lula_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_tfidf_rf = RandomForest_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_tfidf_rf = np.append(predict_lula_tfidf_rf, RandomForest_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_tfidf_rf = np.append(predict_lula_tfidf_rf,RandomForest_lula_tfidf.predict(tfidf_teste(df_lula[i1:], tfidf_lula).toarray()))\n",
    "\n",
    "df_lula['predict_tfidf_RandomForest'] = predict_lula_tfidf_rf\n",
    "\n",
    "np.unique(predict_lula_tfidf_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfc1d1d",
   "metadata": {},
   "source": [
    "### lula - SVM - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5fe1271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([118844,    170, 812716], dtype=int64))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_lula_bw = LinearSVC()\n",
    "svc_lula_bw = svc_lula_bw.fit(X_bw_lula_train.toarray(), Y_lula_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_bw_svc = svc_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_bw_svc = np.append(predict_lula_bw_svc, svc_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_bw_svc = np.append(predict_lula_bw_svc,svc_lula_bw.predict(Bag_of_words_teste(df_lula[i1:], bw_lula).toarray()))\n",
    "\n",
    "df_lula['predict_bw_svc'] = predict_lula_bw_svc\n",
    "\n",
    "np.unique(predict_lula_bw_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7bf3d",
   "metadata": {},
   "source": [
    "### lula - SVM - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de2a47b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 49478,     20, 882232], dtype=int64))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_lula_tfidf = LinearSVC()\n",
    "svc_lula_tfidf = svc_lula_tfidf.fit(X_tfidf_lula_train.toarray(), Y_lula_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_tfidf_svc = svc_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_tfidf_svc = np.append(predict_lula_tfidf_svc, svc_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_tfidf_svc = np.append(predict_lula_tfidf_svc,svc_lula_tfidf.predict(tfidf_teste(df_lula[i1:], tfidf_lula).toarray()))\n",
    "\n",
    "df_lula['predict_tfidf_svc'] = predict_lula_tfidf_svc\n",
    "\n",
    "np.unique(predict_lula_tfidf_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a7a176",
   "metadata": {},
   "source": [
    "### Lula - MLP - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5cc790d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([120073,    484, 811173], dtype=int64))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_lula_bw = MLPClassifier()\n",
    "mlp_lula_bw = mlp_lula_bw.fit(X_bw_lula_train.toarray(), Y_lula_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_bw_mlp = mlp_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_bw_mlp = np.append(predict_lula_bw_mlp, mlp_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_bw_mlp = np.append(predict_lula_bw_mlp,mlp_lula_bw.predict(Bag_of_words_teste(df_lula[i1:], bw_lula).toarray()))\n",
    "\n",
    "df_lula['predict_bw_mlp'] = predict_lula_bw_mlp\n",
    "df_lula['predict_bw_mlp2'] = predict_lula_bw_mlp\n",
    "\n",
    "np.unique(predict_lula_bw_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae763c64",
   "metadata": {},
   "source": [
    "### Lula - MLP - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc07c519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([124659,     97, 806974], dtype=int64))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_lula_tfidf = MLPClassifier()\n",
    "mlp_lula_tfidf = mlp_lula_tfidf.fit(X_tfidf_lula_train.toarray(), Y_lula_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_tfidf_mlp = mlp_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_tfidf_mlp = np.append(predict_lula_tfidf_mlp, mlp_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_tfidf_mlp = np.append(predict_lula_tfidf_mlp,mlp_lula_tfidf.predict(tfidf_teste(df_lula[i1:], tfidf_lula).toarray()))\n",
    "\n",
    "df_lula['predict_tfidf_mlp'] = predict_lula_tfidf_mlp\n",
    "df_lula['predict_tfidf_mlp2'] = predict_lula_tfidf_mlp\n",
    "\n",
    "np.unique(predict_lula_tfidf_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900e6be",
   "metadata": {},
   "source": [
    "# Simone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef15531",
   "metadata": {},
   "source": [
    "### Simone - Arvore de Decisao - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b9cd59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([12480, 71987, 46695], dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_simone_bw = tree.DecisionTreeClassifier()\n",
    "tree_simone_bw = tree_simone_bw.fit(X_bw_simone_train, Y_simone_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_bw_tree = tree_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_bw_tree = np.append(predict_simone_bw_tree, tree_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_bw_tree = np.append(predict_simone_bw_tree,tree_simone_bw.predict(Bag_of_words_teste(df_simone[i1:], bw_simone).toarray()))\n",
    "\n",
    "\n",
    "df_simone['predict_bw_ArvoreDeDecisao'] = predict_simone_bw_tree\n",
    "\n",
    "np.unique(predict_simone_bw_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9f234",
   "metadata": {},
   "source": [
    "### Simone - Arvore de Decisao - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52e0035a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 8107, 73678, 49377], dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_simone_tfidf = tree.DecisionTreeClassifier()\n",
    "tree_simone_tfidf = tree_simone_tfidf.fit(X_tfidf_simone_train, Y_simone_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_tfidf_tree = tree_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_tfidf_tree = np.append(predict_simone_tfidf_tree, tree_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_tfidf_tree = np.append(predict_simone_tfidf_tree,tree_simone_tfidf.predict(tfidf_teste(df_simone[i1:], tfidf_simone).toarray()))\n",
    "\n",
    "\n",
    "df_simone['predict_tfidf_ArvoreDeDecisao'] = predict_simone_tfidf_tree\n",
    "\n",
    "np.unique(predict_simone_tfidf_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b00b40",
   "metadata": {},
   "source": [
    "### Simone - Naive Bayes - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6b39ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([13226, 67265, 50671], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_simone_bw = GaussianNB()\n",
    "GaussianNB_simone_bw = GaussianNB_simone_bw.fit(X_bw_simone_train.toarray(), Y_simone_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_bw_nb = GaussianNB_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_bw_nb = np.append(predict_simone_bw_nb, GaussianNB_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_bw_nb = np.append(predict_simone_bw_nb,GaussianNB_simone_bw.predict(Bag_of_words_teste(df_simone[i1:], bw_simone).toarray()))\n",
    "\n",
    "df_simone['predict_bw_NaiveBayes'] = predict_simone_bw_nb\n",
    "\n",
    "np.unique(predict_simone_bw_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa7e7f",
   "metadata": {},
   "source": [
    "### Simone - Naive Bayes - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "730fa55a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([12320, 61231, 57611], dtype=int64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_simone_tfidf = GaussianNB()\n",
    "GaussianNB_simone_tfidf = GaussianNB_simone_tfidf.fit(X_tfidf_simone_train.toarray(), Y_simone_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_tfidf_nb = GaussianNB_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_tfidf_nb = np.append(predict_simone_tfidf_nb, GaussianNB_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_tfidf_nb = np.append(predict_simone_tfidf_nb,GaussianNB_simone_tfidf.predict(tfidf_teste(df_simone[i1:], tfidf_simone).toarray()))\n",
    "\n",
    "df_simone['predict_tfidf_NaiveBayes'] = predict_simone_tfidf_nb\n",
    "\n",
    "np.unique(predict_simone_tfidf_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4707ef",
   "metadata": {},
   "source": [
    "### Simone - Random Forest - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28bbabf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([  476, 68474, 62212], dtype=int64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_simone_bw = RandomForestClassifier()\n",
    "RandomForest_simone_bw = RandomForest_simone_bw.fit(X_bw_simone_train.toarray(), Y_simone_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_bw_rf = RandomForest_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_bw_rf = np.append(predict_simone_bw_rf, RandomForest_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_bw_rf = np.append(predict_simone_bw_rf,RandomForest_simone_bw.predict(Bag_of_words_teste(df_simone[i1:], bw_simone).toarray()))\n",
    "\n",
    "df_simone['predict_bw_RandomForest'] = predict_simone_bw_rf\n",
    "\n",
    "np.unique(predict_simone_bw_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1249b63",
   "metadata": {},
   "source": [
    "### Simone - Random Forest - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e04c2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([  111, 50220, 80831], dtype=int64))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_simone_tfidf = RandomForestClassifier()\n",
    "RandomForest_simone_tfidf = RandomForest_simone_tfidf.fit(X_tfidf_simone_train.toarray(), Y_simone_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_tfidf_rf = RandomForest_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_tfidf_rf = np.append(predict_simone_tfidf_rf, RandomForest_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_tfidf_rf = np.append(predict_simone_tfidf_rf,RandomForest_simone_tfidf.predict(tfidf_teste(df_simone[i1:], tfidf_simone).toarray()))\n",
    "\n",
    "df_simone['predict_tfidf_RandomForest'] = predict_simone_tfidf_rf\n",
    "\n",
    "np.unique(predict_simone_tfidf_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436514ab",
   "metadata": {},
   "source": [
    "### Simone - SVM - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f3e5b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 6689, 61338, 63135], dtype=int64))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_simone_bw = LinearSVC()\n",
    "svc_simone_bw = svc_simone_bw.fit(X_bw_simone_train.toarray(), Y_simone_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_bw_svc = svc_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_bw_svc = np.append(predict_simone_bw_svc, svc_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_bw_svc = np.append(predict_simone_bw_svc,svc_simone_bw.predict(Bag_of_words_teste(df_simone[i1:], bw_simone).toarray()))\n",
    "\n",
    "df_simone['predict_bw_svc'] = predict_simone_bw_svc\n",
    "\n",
    "np.unique(predict_simone_bw_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cb78bd",
   "metadata": {},
   "source": [
    "### Simone - SVM - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1c69404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 5076, 67126, 58960], dtype=int64))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_simone_tfidf = LinearSVC()\n",
    "svc_simone_tfidf = svc_simone_tfidf.fit(X_tfidf_simone_train.toarray(), Y_simone_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_tfidf_svc = svc_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_tfidf_svc = np.append(predict_simone_tfidf_svc, svc_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_tfidf_svc = np.append(predict_simone_tfidf_svc,svc_simone_tfidf.predict(tfidf_teste(df_simone[i1:], tfidf_simone).toarray()))\n",
    "\n",
    "df_simone['predict_tfidf_svc'] = predict_simone_tfidf_svc\n",
    "\n",
    "np.unique(predict_simone_tfidf_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aaa0f0",
   "metadata": {},
   "source": [
    "### Simone - MLP - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c96f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 6529, 71272, 53361], dtype=int64))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_simone_bw = MLPClassifier()\n",
    "mlp_simone_bw = mlp_simone_bw.fit(X_bw_simone_train.toarray(), Y_simone_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_bw_mlp = mlp_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_bw_mlp = np.append(predict_simone_bw_mlp, mlp_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_bw_mlp = np.append(predict_simone_bw_mlp,mlp_simone_bw.predict(Bag_of_words_teste(df_simone[i1:], bw_simone).toarray()))\n",
    "\n",
    "df_simone['predict_bw_mlp'] = predict_simone_bw_mlp\n",
    "df_simone['predict_bw_mlp2'] = predict_simone_bw_mlp\n",
    "\n",
    "np.unique(predict_simone_bw_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127a6945",
   "metadata": {},
   "source": [
    "### Simone - MLP - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3749320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 8414, 66464, 56284], dtype=int64))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_simone_tfidf = MLPClassifier()\n",
    "mlp_simone_tfidf = mlp_simone_tfidf.fit(X_tfidf_simone_train.toarray(), Y_simone_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_tfidf_mlp = mlp_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_tfidf_mlp = np.append(predict_simone_tfidf_mlp, mlp_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_tfidf_mlp = np.append(predict_simone_tfidf_mlp,mlp_simone_tfidf.predict(tfidf_teste(df_simone[i1:], tfidf_simone).toarray()))\n",
    "\n",
    "df_simone['predict_tfidf_mlp'] = predict_simone_tfidf_mlp\n",
    "df_simone['predict_tfidf_mlp2'] = predict_simone_tfidf_mlp\n",
    "\n",
    "np.unique(predict_simone_tfidf_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fcddfa",
   "metadata": {},
   "source": [
    "# Ciro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f5c918",
   "metadata": {},
   "source": [
    "### Ciro - Arvore de Decisao - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d785071d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([   767,    179, 497120], dtype=int64))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_ciro_bw = tree.DecisionTreeClassifier()\n",
    "tree_ciro_bw = tree_ciro_bw.fit(X_bw_ciro_train, Y_ciro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_bw_tree = tree_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_bw_tree = np.append(predict_ciro_bw_tree, tree_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_bw_tree = np.append(predict_ciro_bw_tree,tree_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:], bw_ciro).toarray()))\n",
    "\n",
    "\n",
    "df_ciro['predict_bw_ArvoreDeDecisao'] = predict_ciro_bw_tree\n",
    "\n",
    "np.unique(predict_ciro_bw_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea7b460",
   "metadata": {},
   "source": [
    "### Ciro - Arvore de Decisao - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbc032a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([   918,    558, 496590], dtype=int64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_ciro_tfidf = tree.DecisionTreeClassifier()\n",
    "tree_ciro_tfidf = tree_ciro_tfidf.fit(X_tfidf_ciro_train, Y_ciro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_tfidf_tree = tree_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_tfidf_tree = np.append(predict_ciro_tfidf_tree, tree_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_tfidf_tree = np.append(predict_ciro_tfidf_tree,tree_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:], tfidf_ciro).toarray()))\n",
    "\n",
    "\n",
    "df_ciro['predict_tfidf_ArvoreDeDecisao'] = predict_ciro_tfidf_tree\n",
    "\n",
    "np.unique(predict_ciro_tfidf_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b4dbdd",
   "metadata": {},
   "source": [
    "### Ciro - Naive Bayes - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0c467c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([  5082,   3206, 489778], dtype=int64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_ciro_bw = GaussianNB()\n",
    "GaussianNB_ciro_bw = GaussianNB_ciro_bw.fit(X_bw_ciro_train.toarray(), Y_ciro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_bw_nb = GaussianNB_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_bw_nb = np.append(predict_ciro_bw_nb, GaussianNB_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_bw_nb = np.append(predict_ciro_bw_nb,GaussianNB_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:], bw_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_bw_NaiveBayes'] = predict_ciro_bw_nb\n",
    "\n",
    "np.unique(predict_ciro_bw_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efeb9e0",
   "metadata": {},
   "source": [
    "### Ciro - Naive Bayes - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9068a107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([  5083,   3211, 489772], dtype=int64))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_ciro_tfidf = GaussianNB()\n",
    "GaussianNB_ciro_tfidf = GaussianNB_ciro_tfidf.fit(X_tfidf_ciro_train.toarray(), Y_ciro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_tfidf_nb = GaussianNB_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_tfidf_nb = np.append(predict_ciro_tfidf_nb, GaussianNB_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_tfidf_nb = np.append(predict_ciro_tfidf_nb,GaussianNB_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:], tfidf_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_tfidf_NaiveBayes'] = predict_ciro_tfidf_nb\n",
    "\n",
    "np.unique(predict_ciro_tfidf_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c288e1",
   "metadata": {},
   "source": [
    "### Ciro - Random Forest - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3749bb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([    12,     12, 498042], dtype=int64))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_ciro_bw = RandomForestClassifier()\n",
    "RandomForest_ciro_bw = RandomForest_ciro_bw.fit(X_bw_ciro_train.toarray(), Y_ciro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_bw_rf = RandomForest_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_bw_rf = np.append(predict_ciro_bw_rf, RandomForest_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_bw_rf = np.append(predict_ciro_bw_rf,RandomForest_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:], bw_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_bw_RandomForest'] = predict_ciro_bw_rf\n",
    "\n",
    "np.unique(predict_ciro_bw_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a83e8cc",
   "metadata": {},
   "source": [
    "### Ciro - Random Forest - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c669787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([    13,     12, 498041], dtype=int64))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_ciro_tfidf = RandomForestClassifier()\n",
    "RandomForest_ciro_tfidf = RandomForest_ciro_tfidf.fit(X_tfidf_ciro_train.toarray(), Y_ciro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_tfidf_rf = RandomForest_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_tfidf_rf = np.append(predict_ciro_tfidf_rf, RandomForest_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_tfidf_rf = np.append(predict_ciro_tfidf_rf,RandomForest_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:], tfidf_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_tfidf_RandomForest'] = predict_ciro_tfidf_rf\n",
    "\n",
    "np.unique(predict_ciro_tfidf_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c330bc",
   "metadata": {},
   "source": [
    "### Ciro - SVM - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2fe398c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([    90,     25, 497951], dtype=int64))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_ciro_bw = LinearSVC()\n",
    "svc_ciro_bw = svc_ciro_bw.fit(X_bw_ciro_train.toarray(), Y_ciro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_bw_svc = svc_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_bw_svc = np.append(predict_ciro_bw_svc, svc_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_bw_svc = np.append(predict_ciro_bw_svc,svc_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:], bw_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_bw_svc'] = predict_ciro_bw_svc\n",
    "\n",
    "np.unique(predict_ciro_bw_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7056f555",
   "metadata": {},
   "source": [
    "### Ciro - SVM - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34fd38ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([    14,     10, 498042], dtype=int64))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_ciro_tfidf = LinearSVC()\n",
    "svc_ciro_tfidf = svc_ciro_tfidf.fit(X_tfidf_ciro_train.toarray(), Y_ciro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_tfidf_svc = svc_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_tfidf_svc = np.append(predict_ciro_tfidf_svc, svc_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_tfidf_svc = np.append(predict_ciro_tfidf_svc,svc_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:], tfidf_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_tfidf_svc'] = predict_ciro_tfidf_svc\n",
    "\n",
    "np.unique(predict_ciro_tfidf_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078936f",
   "metadata": {},
   "source": [
    "### Ciro - MLP - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19ed467c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([    22,     17, 498027], dtype=int64))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_ciro_bw = MLPClassifier()\n",
    "mlp_ciro_bw = mlp_ciro_bw.fit(X_bw_ciro_train.toarray(), Y_ciro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_bw_mlp = mlp_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_bw_mlp = np.append(predict_ciro_bw_mlp, mlp_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_bw_mlp = np.append(predict_ciro_bw_mlp,mlp_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:], bw_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_bw_mlp'] = predict_ciro_bw_mlp\n",
    "df_ciro['predict_bw_mlp2'] = predict_ciro_bw_mlp\n",
    "\n",
    "np.unique(predict_ciro_bw_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aee0ff4",
   "metadata": {},
   "source": [
    "### Ciro - MLP - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7a419b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([    30,     14, 498022], dtype=int64))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_ciro_tfidf = MLPClassifier()\n",
    "mlp_ciro_tfidf = mlp_ciro_tfidf.fit(X_tfidf_ciro_train.toarray(), Y_ciro_train)\n",
    "\n",
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_tfidf_mlp = mlp_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_tfidf_mlp = np.append(predict_ciro_tfidf_mlp, mlp_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_tfidf_mlp = np.append(predict_ciro_tfidf_mlp,mlp_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:], tfidf_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_tfidf_mlp'] = predict_ciro_tfidf_mlp\n",
    "df_ciro['predict_tfidf_mlp2'] = predict_ciro_tfidf_mlp\n",
    "\n",
    "np.unique(predict_ciro_tfidf_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d44e72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro.to_excel('bolsonaro_predict.xlsx')\n",
    "df_lula.to_excel('lula_predict.xlsx')\n",
    "df_simone.to_excel('simone_predict.xlsx')\n",
    "df_ciro.to_excel('ciro_predict.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1c535663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VotacaoPredict(df):\n",
    "    for i in df.index:\n",
    "        pos=0\n",
    "        neu=0\n",
    "        neg=0\n",
    "        for j in ['predict_tfidf_mlp','predict_bw_mlp',\n",
    "                  'predict_tfidf_svc','predict_bw_svc',\n",
    "                 'predict_tfidf_RandomForest','predict_bw_RandomForest',\n",
    "                 'predict_tfidf_NaiveBayes','predict_bw_NaiveBayes',\n",
    "                 'predict_tfidf_ArvoreDeDecisao','predict_bw_ArvoreDeDecisao']:\n",
    "            if (df.loc[i,j]==1):\n",
    "                pos+=1\n",
    "            elif (df.loc[i,j]==0):\n",
    "                neu+=1    \n",
    "            else:\n",
    "                neg+=1\n",
    "            \n",
    "        if(neu>2):\n",
    "            df.loc[i,'VotacaoPredict_ajust'] = 0\n",
    "        elif(neg>2):\n",
    "            df.loc[i,'VotacaoPredict_ajust'] = -1\n",
    "        else:\n",
    "            df.loc[i,'VotacaoPredict_ajust'] = 1\n",
    "        \n",
    "        if((neu>=neg)& (neu>=pos)):\n",
    "            df.loc[i,'VotacaoPredict_norm'] = 0\n",
    "        elif((neg>=pos)& (neg>=neu)):\n",
    "            df.loc[i,'VotacaoPredict_norm'] = -1\n",
    "        else:\n",
    "            df.loc[i,'VotacaoPredict_norm'] = 1     \n",
    "    print(df['VotacaoPredict_ajust'].value_counts())\n",
    "    print(df['VotacaoPredict_norm'].value_counts())        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "51f7c930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Data_post ---\n",
      "2022-10-02T16:59:00Z    100\n",
      "2022-10-01T00:39:00Z    100\n",
      "2022-09-30T10:18:00Z    100\n",
      "2022-09-30T10:21:00Z    100\n",
      "2022-09-30T10:22:00Z    100\n",
      "                       ... \n",
      "2022-08-21T01:44:00Z      1\n",
      "2022-08-16T23:47:00Z      1\n",
      "2022-08-21T22:41:00Z      1\n",
      "2022-08-19T11:04:00Z      1\n",
      "2022-08-20T08:50:00Z      1\n",
      "Name: Data_post, Length: 14274, dtype: int64\n",
      "---- ID ---\n",
      "1.575801e+18    2\n",
      "1.576026e+18    2\n",
      "1.575661e+18    2\n",
      "1.575630e+18    2\n",
      "1.575832e+18    2\n",
      "               ..\n",
      "1.576049e+18    1\n",
      "1.576049e+18    1\n",
      "1.576049e+18    1\n",
      "1.576049e+18    1\n",
      "1.561503e+18    1\n",
      "Name: ID, Length: 498029, dtype: int64\n",
      "---- Texto ---\n",
      "RT @oRodCecim: Paris: a\\n\\nCiro Gomes: https://t.co/L2Bco470d5                                                                                                                                                                                                                                             4783\n",
      "RT @runmand: nem a cidade natal de ciro apoiando ele                                                                                                                                                                                                                                                       3655\n",
      "RT @alamoju: segundo o datafolha após a participação do padre que não é padre no debate, o ateísmo subiu 8%, ultrapassando assim o ciro gom…                                                                                                                                                               3277\n",
      "RT @leonelbrizolarj: Ciro Gomes cego de ódio e pensando somente em seu projeto pessoal e não no futuro do Brasil se faz de vítima, fingindo…                                                                                                                                                               3068\n",
      "RT @barbaragancia: Mario Sérgio Conti acaba de dizer com todas as letras na Globonews: \"O Orçamento Secreto do Bozo é o maior escândalo de…                                                                                                                                                                2490\n",
      "                                                                                                                                                                                                                                                                                                           ... \n",
      "@Mathe_noberto Vota no Ciro Gomes 12, ele tem um PROJETO para o Brasil, ficha limpa                                                                                                                                                                                                                           1\n",
      "@emimotopapi o ciro rompeu com os irmãos né, pq eles apoiaram o lula                                                                                                                                                                                                                                          1\n",
      "@unsttabIe Se puder, dá uma oportunidade pro CIRO 1️⃣2️⃣\\nO cara tá na quarta, talvez última tentativa, e tem um Projeto bem acabado pro Brasil com foco na Educação, Reindustrialização, combate à desigualdade social e geração de empregos.\\nConheça melhor suas propostas:\\nhttps://t.co/DK2BcJlK22       1\n",
      "@Kramer_Alisson Bora de Ciro Gomes 12. Bora para um projeto para país. 🌹✊\\nChega de políticos corruptos, que só querem o poder e não tem uma proposta. Vamos de 12✊                                                                                                                                           1\n",
      "@JosAntn70295004 @Carlosdinizsilv Pois é, mas aí caímos no círculo vicioso (pernicioso), votando no outro polo. Caramba! Urge sair disso para não ficarmos na mesmice eterna, q nos faz mal, nos divide. Votemos em Soraya, ou Tebet, ou D'Ávila, ou Ciro... São fracos? Mudemos na próxima.                  1\n",
      "Name: Texto, Length: 192734, dtype: int64\n",
      "---- Eh_RT ---\n",
      "S    335662\n",
      "N    162404\n",
      "Name: Eh_RT, dtype: int64\n",
      "---- novo_texto ---\n",
      "['orodcecim', 'paril', 'cir', 'gom', 'lbcod']                                                                                                                                                                                                                    4783\n",
      "['runmand', 'cidad', 'natal', 'cir', 'apoi']                                                                                                                                                                                                                     3655\n",
      "['alamoju', 'segund', 'datafolh', 'apos', 'particip', 'padr', 'padr', 'debat', 'ateism', 'sub', 'ultrapas', 'asim', 'cir', 'gom']                                                                                                                                3277\n",
      "['leonelbrizolarj', 'cir', 'gom', 'ceg', 'odi', 'pens', 'soment', 'projet', 'pesoal', 'futur', 'brasil', 'faz', 'vitim', 'fingindo']                                                                                                                             3068\n",
      "['barbaraganc', 'mari', 'sergi', 'cont', 'acab', 'diz', 'tod', 'letr', 'globonew', 'orc', 'secret', 'boz', 'mai', 'escandal', 'de']                                                                                                                              2490\n",
      "                                                                                                                                                                                                                                                                 ... \n",
      "['sandyjoana', 'oportun', 'pra', 'sab', 'govern', 'lul', 'hj', 'sofr', 'govern', 'bolzonar', 'cir', 'prepar', 'qualific', 'projet', 'pais', 'cir', 'nhnvaztnm']                                                                                                     1\n",
      "['rev', 'part', 'debat', 'cir', 'apont', 'corupc', 'bolsonar', 'boz', 'neg', 'orc', 'secret', 'fal', 'pod', 'faz', 'nad', 'cir', 'direit', 'fal', 'pouc', 'ped', 'entend', 'cen', 'fic', 'tao', 'apere', 'quant']                                                   1\n",
      "['kehrian', 'pud', 'da', 'oportun', 'pro', 'cir', '', 'car', 'quart', 'talv', 'ult', 'tent', 'projet', 'bem', 'acab', 'pro', 'brasil', 'foc', 'educ', 'reindustri', 'combat', 'desigualdad', 'soc', 'ger', 'empreg', 'conhec', 'melhor', 'propost', 'dkbcjh']       1\n",
      "['peso', 'vem', 'fal', '\"', 'vot', 'cir', 'vai', 'vot', 'jog', 'fora\"', 'vai', 'tom', 'cu', 'vot', 'quis', 'gal', 'chat']                                                                                                                                           1\n",
      "['josantn', 'carlosdinizsilv', 'poi', 'ai', 'caim', 'circul', 'vici', 'pernici', 'vot', 'outr', 'pol', 'caramb', 'urg', 'sair', 'dis', 'fic', 'mesm', 'etern', 'faz', 'mal', 'divid', 'vot', 'soray', 'tebet', 'avil', 'cir', 'frac', 'mud', 'prox']                1\n",
      "Name: novo_texto, Length: 190369, dtype: int64\n",
      "---- predict_bw_ArvoreDeDecisao ---\n",
      " 1    497120\n",
      "-1       767\n",
      " 0       179\n",
      "Name: predict_bw_ArvoreDeDecisao, dtype: int64\n",
      "---- predict_tfidf_ArvoreDeDecisao ---\n",
      " 1    496590\n",
      "-1       918\n",
      " 0       558\n",
      "Name: predict_tfidf_ArvoreDeDecisao, dtype: int64\n",
      "---- predict_bw_NaiveBayes ---\n",
      " 1    489778\n",
      "-1      5082\n",
      " 0      3206\n",
      "Name: predict_bw_NaiveBayes, dtype: int64\n",
      "---- predict_tfidf_NaiveBayes ---\n",
      " 1    489772\n",
      "-1      5083\n",
      " 0      3211\n",
      "Name: predict_tfidf_NaiveBayes, dtype: int64\n",
      "---- predict_bw_RandomForest ---\n",
      " 1    498042\n",
      "-1        12\n",
      " 0        12\n",
      "Name: predict_bw_RandomForest, dtype: int64\n",
      "---- predict_tfidf_RandomForest ---\n",
      " 1    498041\n",
      "-1        13\n",
      " 0        12\n",
      "Name: predict_tfidf_RandomForest, dtype: int64\n",
      "---- predict_bw_svc ---\n",
      " 1    497951\n",
      "-1        90\n",
      " 0        25\n",
      "Name: predict_bw_svc, dtype: int64\n",
      "---- predict_tfidf_svc ---\n",
      " 1    498042\n",
      "-1        14\n",
      " 0        10\n",
      "Name: predict_tfidf_svc, dtype: int64\n",
      "---- predict_bw_mlp ---\n",
      " 1    498027\n",
      "-1        22\n",
      " 0        17\n",
      "Name: predict_bw_mlp, dtype: int64\n",
      "---- predict_bw_mlp2 ---\n",
      " 1    498027\n",
      "-1        22\n",
      " 0        17\n",
      "Name: predict_bw_mlp2, dtype: int64\n",
      "---- predict_tfidf_mlp ---\n",
      " 1    498022\n",
      "-1        30\n",
      " 0        14\n",
      "Name: predict_tfidf_mlp, dtype: int64\n",
      "---- predict_tfidf_mlp2 ---\n",
      " 1    498022\n",
      "-1        30\n",
      " 0        14\n",
      "Name: predict_tfidf_mlp2, dtype: int64\n",
      "---- VotacaoPredict_ajust ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0    497961\n",
      " 0.0        57\n",
      "-1.0        48\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n",
      "---- VotacaoPredict_norm ---\n",
      " 1.0    498035\n",
      "-1.0        18\n",
      " 0.0        13\n",
      "Name: VotacaoPredict_norm, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for c in df_ciro_predict2.columns:\n",
    "    print (\"---- %s ---\" % c)\n",
    "    print (df_ciro_predict2[c].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "36d3635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0    715776\n",
      "-1.0    226020\n",
      " 0.0      4642\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n",
      " 1.0    850903\n",
      "-1.0     92718\n",
      " 0.0      2817\n",
      "Name: VotacaoPredict_norm, dtype: int64\n",
      " 1.0    744842\n",
      "-1.0    186772\n",
      " 0.0       116\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n",
      " 1.0    856444\n",
      "-1.0     75247\n",
      " 0.0        39\n",
      "Name: VotacaoPredict_norm, dtype: int64\n",
      " 0.0    90119\n",
      " 1.0    34843\n",
      "-1.0     6200\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n",
      " 0.0    68633\n",
      " 1.0    57739\n",
      "-1.0     4790\n",
      "Name: VotacaoPredict_norm, dtype: int64\n",
      " 1.0    497961\n",
      " 0.0        57\n",
      "-1.0        48\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n",
      " 1.0    498035\n",
      "-1.0        18\n",
      " 0.0        13\n",
      "Name: VotacaoPredict_norm, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_bolsonaro_predict2 = VotacaoPredict(df_bolsonaro)\n",
    "df_lula_predict2 = VotacaoPredict(df_lula)\n",
    "df_simone_predict2 = VotacaoPredict(df_simone)\n",
    "df_ciro_predict2 = VotacaoPredict(df_ciro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7d94206a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0    496314\n",
      "-1.0    429653\n",
      " 0.0     20471\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n",
      "-1.0    478582\n",
      " 1.0    445607\n",
      " 0.0      7541\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n",
      " 0.0    99096\n",
      " 1.0    25411\n",
      "-1.0     6655\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n",
      " 1.0    489348\n",
      "-1.0      5379\n",
      " 0.0      3339\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_bolsonaro_predict2 = VotacaoPredict(df_bolsonaro)\n",
    "df_lula_predict2 = VotacaoPredict(df_lula)\n",
    "df_simone_predict2 = VotacaoPredict(df_simone)\n",
    "df_ciro_predict2 = VotacaoPredict(df_ciro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c84c703c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0    715776\n",
      "-1.0    226020\n",
      " 0.0      4642\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n",
      " 1.0    856444\n",
      "-1.0     75247\n",
      " 0.0        39\n",
      "Name: VotacaoPredict_norm, dtype: int64\n",
      " 0.0    68633\n",
      " 1.0    57739\n",
      "-1.0     4790\n",
      "Name: VotacaoPredict_norm, dtype: int64\n",
      " 1.0    498035\n",
      "-1.0        18\n",
      " 0.0        13\n",
      "Name: VotacaoPredict_norm, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_bolsonaro_predict2['VotacaoPredict_ajust'].value_counts())\n",
    "print(df_lula_predict2['VotacaoPredict_norm'].value_counts())\n",
    "print(df_simone_predict2['VotacaoPredict_norm'].value_counts())\n",
    "print(df_ciro_predict2['VotacaoPredict_norm'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123b9d60",
   "metadata": {},
   "source": [
    "## df_lula_predict2.loc[931705,'VotacaoPredict_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "86c9cc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p    10322\n",
       "n     1758\n",
       "x       25\n",
       "Name: Sentimento, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lula_train['Sentimento'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "230eb27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    744842\n",
       "-1.0    186772\n",
       " 0.0       116\n",
       "Name: VotacaoPredict_ajust, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lula_predict2['VotacaoPredict_ajust'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "efe66014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18        RT @futurehadid: lula assistindo a dua lipa pe...\n",
       "23        @RicardoBrisa55 @flferronato @TSEjusbr https:/...\n",
       "48        RT @kimluvthv: lula assistindo taehyung cantar...\n",
       "71        RT @JoaquinTeixeira: URNAS FECHADAS EM CUBA 🇨🇺...\n",
       "81                  lula vencendo em todos os países veeeei\n",
       "                                ...                        \n",
       "931703    Em entrevista ao podcast Podpah, Lula erra ao ...\n",
       "931704    RT @LeonMenez: Esse aqui é pra você compartilh...\n",
       "931705    @roxmo O Lula deveria está inelegível pelo mal...\n",
       "931716    RT @BrazilFight: EDUARDO BOLSONARO CONVIDA LUL...\n",
       "931725    RT @ClaudiaBahia_13: Se tem um homem no brasil...\n",
       "Name: Texto, Length: 186772, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lula_predict2[df_lula_predict2['VotacaoPredict_ajust']==-1]['Texto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dec54a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>VotacaoPredict_ajust</th>\n",
       "      <th>VotacaoPredict_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @Carlinhosmaiaof: Indo votar 13 indo votar ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @lelispatricia: LULA PRESIDENTE HOJE!!!! ⭐️❤️</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>espero que o lula tenha sentido a dedada forte...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @purpleumbrelIa: gente eu to tao ansiosa p ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @BlogdoNoblat: Lula se elege hoje?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931725</th>\n",
       "      <td>RT @ClaudiaBahia_13: Se tem um homem no brasil...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931726</th>\n",
       "      <td>RT @IvanValente: Lula e Bolsonaro estarão posi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931727</th>\n",
       "      <td>Lula sempre! https://t.co/wGjjcnKh6E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931728</th>\n",
       "      <td>RT @ricardope: @OGloboPolitica A campanha do L...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931729</th>\n",
       "      <td>RT @kimpaim: Lula quer que a população \"enfren...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>931730 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Texto  \\\n",
       "0       RT @Carlinhosmaiaof: Indo votar 13 indo votar ...   \n",
       "1        RT @lelispatricia: LULA PRESIDENTE HOJE!!!! ⭐️❤️   \n",
       "2       espero que o lula tenha sentido a dedada forte...   \n",
       "3       RT @purpleumbrelIa: gente eu to tao ansiosa p ...   \n",
       "4                   RT @BlogdoNoblat: Lula se elege hoje?   \n",
       "...                                                   ...   \n",
       "931725  RT @ClaudiaBahia_13: Se tem um homem no brasil...   \n",
       "931726  RT @IvanValente: Lula e Bolsonaro estarão posi...   \n",
       "931727               Lula sempre! https://t.co/wGjjcnKh6E   \n",
       "931728  RT @ricardope: @OGloboPolitica A campanha do L...   \n",
       "931729  RT @kimpaim: Lula quer que a população \"enfren...   \n",
       "\n",
       "        VotacaoPredict_ajust  VotacaoPredict_norm  \n",
       "0                        1.0                  1.0  \n",
       "1                        1.0                  1.0  \n",
       "2                        1.0                  1.0  \n",
       "3                        1.0                  1.0  \n",
       "4                        1.0                  1.0  \n",
       "...                      ...                  ...  \n",
       "931725                  -1.0                  1.0  \n",
       "931726                   1.0                  1.0  \n",
       "931727                   1.0                  1.0  \n",
       "931728                   1.0                  1.0  \n",
       "931729                   1.0                  1.0  \n",
       "\n",
       "[931730 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lula_predict2[['Texto', 'VotacaoPredict_ajust','VotacaoPredict_norm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "94eecce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>VotacaoPredict_ajust</th>\n",
       "      <th>VotacaoPredict_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @Carlinhosmaiaof: Indo votar 13 indo votar ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @lelispatricia: LULA PRESIDENTE HOJE!!!! ⭐️❤️</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>espero que o lula tenha sentido a dedada forte...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @purpleumbrelIa: gente eu to tao ansiosa p ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @BlogdoNoblat: Lula se elege hoje?</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931725</th>\n",
       "      <td>RT @ClaudiaBahia_13: Se tem um homem no brasil...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931726</th>\n",
       "      <td>RT @IvanValente: Lula e Bolsonaro estarão posi...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931727</th>\n",
       "      <td>Lula sempre! https://t.co/wGjjcnKh6E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931728</th>\n",
       "      <td>RT @ricardope: @OGloboPolitica A campanha do L...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931729</th>\n",
       "      <td>RT @kimpaim: Lula quer que a população \"enfren...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>931730 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Texto  \\\n",
       "0       RT @Carlinhosmaiaof: Indo votar 13 indo votar ...   \n",
       "1        RT @lelispatricia: LULA PRESIDENTE HOJE!!!! ⭐️❤️   \n",
       "2       espero que o lula tenha sentido a dedada forte...   \n",
       "3       RT @purpleumbrelIa: gente eu to tao ansiosa p ...   \n",
       "4                   RT @BlogdoNoblat: Lula se elege hoje?   \n",
       "...                                                   ...   \n",
       "931725  RT @ClaudiaBahia_13: Se tem um homem no brasil...   \n",
       "931726  RT @IvanValente: Lula e Bolsonaro estarão posi...   \n",
       "931727               Lula sempre! https://t.co/wGjjcnKh6E   \n",
       "931728  RT @ricardope: @OGloboPolitica A campanha do L...   \n",
       "931729  RT @kimpaim: Lula quer que a população \"enfren...   \n",
       "\n",
       "        VotacaoPredict_ajust  VotacaoPredict_norm  \n",
       "0                       -1.0                  1.0  \n",
       "1                       -1.0                  1.0  \n",
       "2                        1.0                  1.0  \n",
       "3                        1.0                  1.0  \n",
       "4                       -1.0                  1.0  \n",
       "...                      ...                  ...  \n",
       "931725                  -1.0                  1.0  \n",
       "931726                  -1.0                  1.0  \n",
       "931727                   0.0                  1.0  \n",
       "931728                  -1.0                  1.0  \n",
       "931729                   1.0                  1.0  \n",
       "\n",
       "[931730 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lula_predict[['Texto', 'VotacaoPredict_ajust','VotacaoPredict_norm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "393624ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro_predict2.to_excel('bolsonaro_resultado2.xlsx')\n",
    "df_lula_predict2.to_excel('lula_resultado2.xlsx')\n",
    "df_simone_predict2.to_excel('simone_resultado2.xlsx')\n",
    "df_ciro_predict2.to_excel('ciro_resultado2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a483432f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_post</th>\n",
       "      <th>ID</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Eh_RT</th>\n",
       "      <th>novo_texto</th>\n",
       "      <th>predict_bw_ArvoreDeDecisao</th>\n",
       "      <th>predict_tfidf_ArvoreDeDecisao</th>\n",
       "      <th>predict_bw_NaiveBayes</th>\n",
       "      <th>predict_tfidf_NaiveBayes</th>\n",
       "      <th>predict_bw_RandomForest</th>\n",
       "      <th>predict_tfidf_RandomForest</th>\n",
       "      <th>predict_bw_svc</th>\n",
       "      <th>predict_tfidf_svc</th>\n",
       "      <th>predict_bw_mlp</th>\n",
       "      <th>predict_bw_mlp2</th>\n",
       "      <th>predict_tfidf_mlp</th>\n",
       "      <th>predict_tfidf_mlp2</th>\n",
       "      <th>VotacaoPredict_ajust</th>\n",
       "      <th>VotacaoPredict_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-02T16:59:00Z</td>\n",
       "      <td>1.576618e+18</td>\n",
       "      <td>RT @lucasrohan: BOLSONARO PERDENDO DE LAVADA E...</td>\n",
       "      <td>S</td>\n",
       "      <td>['lucasrohan', 'bolsonar', 'perd', 'lav', 'bra...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-02T16:59:00Z</td>\n",
       "      <td>1.576618e+18</td>\n",
       "      <td>@ArturSalvador5 @FusionFPX @DaviPer38812310 @j...</td>\n",
       "      <td>N</td>\n",
       "      <td>['artursalv', 'fusionfpx', 'davip', 'josim', '...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-02T16:59:00Z</td>\n",
       "      <td>1.576618e+18</td>\n",
       "      <td>RT @JenoOliveiraa: No Japão Bolsonaro tem vitó...</td>\n",
       "      <td>S</td>\n",
       "      <td>['jenoliveira', 'jap', 'bolsonar', 'vitor', 'e...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-02T16:59:00Z</td>\n",
       "      <td>1.576618e+18</td>\n",
       "      <td>RT @reinaldoazevedo: Eleitor pilantra de Bolso...</td>\n",
       "      <td>S</td>\n",
       "      <td>['reinaldoazeved', 'elei', 'pilantr', 'bolsona...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-02T16:59:00Z</td>\n",
       "      <td>1.576618e+18</td>\n",
       "      <td>RT @AugustoNPistola: Com a liderança do Bolson...</td>\n",
       "      <td>S</td>\n",
       "      <td>['augustonpistol', 'lideranc', 'bolsonar', 'pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946433</th>\n",
       "      <td>2022-08-21T23:59:00Z</td>\n",
       "      <td>1.561503e+18</td>\n",
       "      <td>RT @IvanValente: Lula e Bolsonaro estarão posi...</td>\n",
       "      <td>S</td>\n",
       "      <td>['ivanval', 'lul', 'bolsonar', 'est', 'posicio...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946434</th>\n",
       "      <td>2022-08-21T23:59:00Z</td>\n",
       "      <td>1.561503e+18</td>\n",
       "      <td>@JoelPinheiro85 No fundo você está querendo de...</td>\n",
       "      <td>N</td>\n",
       "      <td>['joelpinh', 'fund', 'quer', 'diz', 'bolsonar'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946435</th>\n",
       "      <td>2022-08-21T23:59:00Z</td>\n",
       "      <td>1.561503e+18</td>\n",
       "      <td>RT @TradutordoBR: Você também vai assistir a e...</td>\n",
       "      <td>S</td>\n",
       "      <td>['tradutordobr', 'vai', 'asist', 'entrev', 'bo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946436</th>\n",
       "      <td>2022-08-21T23:59:00Z</td>\n",
       "      <td>1.561503e+18</td>\n",
       "      <td>RT @genriquez191: *Bolsonaro alfineta Macron a...</td>\n",
       "      <td>S</td>\n",
       "      <td>['genriqu', 'bolsonar', 'alfinet', 'macron', '...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946437</th>\n",
       "      <td>2022-08-21T23:59:00Z</td>\n",
       "      <td>1.561503e+18</td>\n",
       "      <td>RT @fellipebambam: Nosso Presidente Bolsonaro ...</td>\n",
       "      <td>S</td>\n",
       "      <td>['felipebamb', 'presid', 'bolsonar', 'michel',...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>946438 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Data_post            ID  \\\n",
       "0       2022-10-02T16:59:00Z  1.576618e+18   \n",
       "1       2022-10-02T16:59:00Z  1.576618e+18   \n",
       "2       2022-10-02T16:59:00Z  1.576618e+18   \n",
       "3       2022-10-02T16:59:00Z  1.576618e+18   \n",
       "4       2022-10-02T16:59:00Z  1.576618e+18   \n",
       "...                      ...           ...   \n",
       "946433  2022-08-21T23:59:00Z  1.561503e+18   \n",
       "946434  2022-08-21T23:59:00Z  1.561503e+18   \n",
       "946435  2022-08-21T23:59:00Z  1.561503e+18   \n",
       "946436  2022-08-21T23:59:00Z  1.561503e+18   \n",
       "946437  2022-08-21T23:59:00Z  1.561503e+18   \n",
       "\n",
       "                                                    Texto Eh_RT  \\\n",
       "0       RT @lucasrohan: BOLSONARO PERDENDO DE LAVADA E...     S   \n",
       "1       @ArturSalvador5 @FusionFPX @DaviPer38812310 @j...     N   \n",
       "2       RT @JenoOliveiraa: No Japão Bolsonaro tem vitó...     S   \n",
       "3       RT @reinaldoazevedo: Eleitor pilantra de Bolso...     S   \n",
       "4       RT @AugustoNPistola: Com a liderança do Bolson...     S   \n",
       "...                                                   ...   ...   \n",
       "946433  RT @IvanValente: Lula e Bolsonaro estarão posi...     S   \n",
       "946434  @JoelPinheiro85 No fundo você está querendo de...     N   \n",
       "946435  RT @TradutordoBR: Você também vai assistir a e...     S   \n",
       "946436  RT @genriquez191: *Bolsonaro alfineta Macron a...     S   \n",
       "946437  RT @fellipebambam: Nosso Presidente Bolsonaro ...     S   \n",
       "\n",
       "                                               novo_texto  \\\n",
       "0       ['lucasrohan', 'bolsonar', 'perd', 'lav', 'bra...   \n",
       "1       ['artursalv', 'fusionfpx', 'davip', 'josim', '...   \n",
       "2       ['jenoliveira', 'jap', 'bolsonar', 'vitor', 'e...   \n",
       "3       ['reinaldoazeved', 'elei', 'pilantr', 'bolsona...   \n",
       "4       ['augustonpistol', 'lideranc', 'bolsonar', 'pe...   \n",
       "...                                                   ...   \n",
       "946433  ['ivanval', 'lul', 'bolsonar', 'est', 'posicio...   \n",
       "946434  ['joelpinh', 'fund', 'quer', 'diz', 'bolsonar'...   \n",
       "946435  ['tradutordobr', 'vai', 'asist', 'entrev', 'bo...   \n",
       "946436  ['genriqu', 'bolsonar', 'alfinet', 'macron', '...   \n",
       "946437  ['felipebamb', 'presid', 'bolsonar', 'michel',...   \n",
       "\n",
       "        predict_bw_ArvoreDeDecisao  predict_tfidf_ArvoreDeDecisao  \\\n",
       "0                               -1                              1   \n",
       "1                               -1                             -1   \n",
       "2                               -1                              1   \n",
       "3                                1                              1   \n",
       "4                                1                              1   \n",
       "...                            ...                            ...   \n",
       "946433                           1                              1   \n",
       "946434                           1                              1   \n",
       "946435                           1                              1   \n",
       "946436                           1                              1   \n",
       "946437                          -1                              1   \n",
       "\n",
       "        predict_bw_NaiveBayes  predict_tfidf_NaiveBayes  \\\n",
       "0                          -1                        -1   \n",
       "1                          -1                        -1   \n",
       "2                           1                         1   \n",
       "3                           1                         1   \n",
       "4                           1                         1   \n",
       "...                       ...                       ...   \n",
       "946433                      1                         1   \n",
       "946434                      1                         1   \n",
       "946435                      1                         1   \n",
       "946436                     -1                        -1   \n",
       "946437                      1                         1   \n",
       "\n",
       "        predict_bw_RandomForest  predict_tfidf_RandomForest  predict_bw_svc  \\\n",
       "0                             1                           1               1   \n",
       "1                            -1                          -1              -1   \n",
       "2                             1                           1              -1   \n",
       "3                             1                           1              -1   \n",
       "4                             1                           1               1   \n",
       "...                         ...                         ...             ...   \n",
       "946433                        1                           1               1   \n",
       "946434                        1                           1               1   \n",
       "946435                        1                           1               1   \n",
       "946436                        1                           1               1   \n",
       "946437                        1                           1               1   \n",
       "\n",
       "        predict_tfidf_svc  predict_bw_mlp  predict_bw_mlp2  predict_tfidf_mlp  \\\n",
       "0                       1               1                1                  1   \n",
       "1                      -1              -1               -1                 -1   \n",
       "2                       1              -1               -1                 -1   \n",
       "3                      -1              -1               -1                  1   \n",
       "4                       1               1                1                  1   \n",
       "...                   ...             ...              ...                ...   \n",
       "946433                  1               1                1                  1   \n",
       "946434                  1               1                1                  1   \n",
       "946435                  1               1                1                  1   \n",
       "946436                  1               1                1                  1   \n",
       "946437                  1               1                1                  1   \n",
       "\n",
       "        predict_tfidf_mlp2  VotacaoPredict_ajust  VotacaoPredict_norm  \n",
       "0                        1                  -1.0                  1.0  \n",
       "1                       -1                  -1.0                 -1.0  \n",
       "2                       -1                  -1.0                 -1.0  \n",
       "3                        1                  -1.0                  1.0  \n",
       "4                        1                   1.0                  1.0  \n",
       "...                    ...                   ...                  ...  \n",
       "946433                   1                   1.0                  1.0  \n",
       "946434                   1                   1.0                  1.0  \n",
       "946435                   1                   1.0                  1.0  \n",
       "946436                   1                  -1.0                  1.0  \n",
       "946437                   1                   1.0                  1.0  \n",
       "\n",
       "[946438 rows x 19 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bolsonaro_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "042da1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    507782\n",
       "-1.0    438656\n",
       "Name: VotacaoPredict_ajust, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bolsonaro_predict['VotacaoPredict_ajust'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d226e410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_post</th>\n",
       "      <th>ID</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Eh_RT</th>\n",
       "      <th>novo_texto</th>\n",
       "      <th>predict_bw_ArvoreDeDecisao</th>\n",
       "      <th>predict_tfidf_ArvoreDeDecisao</th>\n",
       "      <th>predict_bw_NaiveBayes</th>\n",
       "      <th>predict_tfidf_NaiveBayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-02T16:59:00Z</td>\n",
       "      <td>1.576618e+18</td>\n",
       "      <td>RT @lucasrohan: BOLSONARO PERDENDO DE LAVADA E...</td>\n",
       "      <td>S</td>\n",
       "      <td>['lucasrohan', 'bolsonar', 'perd', 'lav', 'bra...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-02T16:59:00Z</td>\n",
       "      <td>1.576618e+18</td>\n",
       "      <td>@ArturSalvador5 @FusionFPX @DaviPer38812310 @j...</td>\n",
       "      <td>N</td>\n",
       "      <td>['artursalv', 'fusionfpx', 'davip', 'josim', '...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-02T16:59:00Z</td>\n",
       "      <td>1.576618e+18</td>\n",
       "      <td>RT @JenoOliveiraa: No Japão Bolsonaro tem vitó...</td>\n",
       "      <td>S</td>\n",
       "      <td>['jenoliveira', 'jap', 'bolsonar', 'vitor', 'e...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-02T16:59:00Z</td>\n",
       "      <td>1.576618e+18</td>\n",
       "      <td>RT @reinaldoazevedo: Eleitor pilantra de Bolso...</td>\n",
       "      <td>S</td>\n",
       "      <td>['reinaldoazeved', 'elei', 'pilantr', 'bolsona...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-02T16:59:00Z</td>\n",
       "      <td>1.576618e+18</td>\n",
       "      <td>RT @AugustoNPistola: Com a liderança do Bolson...</td>\n",
       "      <td>S</td>\n",
       "      <td>['augustonpistol', 'lideranc', 'bolsonar', 'pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946433</th>\n",
       "      <td>2022-08-21T23:59:00Z</td>\n",
       "      <td>1.561503e+18</td>\n",
       "      <td>RT @IvanValente: Lula e Bolsonaro estarão posi...</td>\n",
       "      <td>S</td>\n",
       "      <td>['ivanval', 'lul', 'bolsonar', 'est', 'posicio...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946434</th>\n",
       "      <td>2022-08-21T23:59:00Z</td>\n",
       "      <td>1.561503e+18</td>\n",
       "      <td>@JoelPinheiro85 No fundo você está querendo de...</td>\n",
       "      <td>N</td>\n",
       "      <td>['joelpinh', 'fund', 'quer', 'diz', 'bolsonar'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946435</th>\n",
       "      <td>2022-08-21T23:59:00Z</td>\n",
       "      <td>1.561503e+18</td>\n",
       "      <td>RT @TradutordoBR: Você também vai assistir a e...</td>\n",
       "      <td>S</td>\n",
       "      <td>['tradutordobr', 'vai', 'asist', 'entrev', 'bo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946436</th>\n",
       "      <td>2022-08-21T23:59:00Z</td>\n",
       "      <td>1.561503e+18</td>\n",
       "      <td>RT @genriquez191: *Bolsonaro alfineta Macron a...</td>\n",
       "      <td>S</td>\n",
       "      <td>['genriqu', 'bolsonar', 'alfinet', 'macron', '...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946437</th>\n",
       "      <td>2022-08-21T23:59:00Z</td>\n",
       "      <td>1.561503e+18</td>\n",
       "      <td>RT @fellipebambam: Nosso Presidente Bolsonaro ...</td>\n",
       "      <td>S</td>\n",
       "      <td>['felipebamb', 'presid', 'bolsonar', 'michel',...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>946438 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Data_post            ID  \\\n",
       "0       2022-10-02T16:59:00Z  1.576618e+18   \n",
       "1       2022-10-02T16:59:00Z  1.576618e+18   \n",
       "2       2022-10-02T16:59:00Z  1.576618e+18   \n",
       "3       2022-10-02T16:59:00Z  1.576618e+18   \n",
       "4       2022-10-02T16:59:00Z  1.576618e+18   \n",
       "...                      ...           ...   \n",
       "946433  2022-08-21T23:59:00Z  1.561503e+18   \n",
       "946434  2022-08-21T23:59:00Z  1.561503e+18   \n",
       "946435  2022-08-21T23:59:00Z  1.561503e+18   \n",
       "946436  2022-08-21T23:59:00Z  1.561503e+18   \n",
       "946437  2022-08-21T23:59:00Z  1.561503e+18   \n",
       "\n",
       "                                                    Texto Eh_RT  \\\n",
       "0       RT @lucasrohan: BOLSONARO PERDENDO DE LAVADA E...     S   \n",
       "1       @ArturSalvador5 @FusionFPX @DaviPer38812310 @j...     N   \n",
       "2       RT @JenoOliveiraa: No Japão Bolsonaro tem vitó...     S   \n",
       "3       RT @reinaldoazevedo: Eleitor pilantra de Bolso...     S   \n",
       "4       RT @AugustoNPistola: Com a liderança do Bolson...     S   \n",
       "...                                                   ...   ...   \n",
       "946433  RT @IvanValente: Lula e Bolsonaro estarão posi...     S   \n",
       "946434  @JoelPinheiro85 No fundo você está querendo de...     N   \n",
       "946435  RT @TradutordoBR: Você também vai assistir a e...     S   \n",
       "946436  RT @genriquez191: *Bolsonaro alfineta Macron a...     S   \n",
       "946437  RT @fellipebambam: Nosso Presidente Bolsonaro ...     S   \n",
       "\n",
       "                                               novo_texto  \\\n",
       "0       ['lucasrohan', 'bolsonar', 'perd', 'lav', 'bra...   \n",
       "1       ['artursalv', 'fusionfpx', 'davip', 'josim', '...   \n",
       "2       ['jenoliveira', 'jap', 'bolsonar', 'vitor', 'e...   \n",
       "3       ['reinaldoazeved', 'elei', 'pilantr', 'bolsona...   \n",
       "4       ['augustonpistol', 'lideranc', 'bolsonar', 'pe...   \n",
       "...                                                   ...   \n",
       "946433  ['ivanval', 'lul', 'bolsonar', 'est', 'posicio...   \n",
       "946434  ['joelpinh', 'fund', 'quer', 'diz', 'bolsonar'...   \n",
       "946435  ['tradutordobr', 'vai', 'asist', 'entrev', 'bo...   \n",
       "946436  ['genriqu', 'bolsonar', 'alfinet', 'macron', '...   \n",
       "946437  ['felipebamb', 'presid', 'bolsonar', 'michel',...   \n",
       "\n",
       "        predict_bw_ArvoreDeDecisao  predict_tfidf_ArvoreDeDecisao  \\\n",
       "0                               -1                              1   \n",
       "1                               -1                             -1   \n",
       "2                               -1                              1   \n",
       "3                                1                              1   \n",
       "4                                1                              1   \n",
       "...                            ...                            ...   \n",
       "946433                           1                              1   \n",
       "946434                           1                              1   \n",
       "946435                           1                              1   \n",
       "946436                           1                              1   \n",
       "946437                          -1                              1   \n",
       "\n",
       "        predict_bw_NaiveBayes  predict_tfidf_NaiveBayes  \n",
       "0                          -1                        -1  \n",
       "1                          -1                        -1  \n",
       "2                           1                         1  \n",
       "3                           1                         1  \n",
       "4                           1                         1  \n",
       "...                       ...                       ...  \n",
       "946433                      1                         1  \n",
       "946434                      1                         1  \n",
       "946435                      1                         1  \n",
       "946436                     -1                        -1  \n",
       "946437                      1                         1  \n",
       "\n",
       "[946438 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_bolsonaro = pd.read_excel('bolsonaro_predict1.xlsx', index_col=0)\n",
    "# df_lula = pd.read_excel('lula_predict1.xlsx', index_col=0)\n",
    "# df_simone = pd.read_excel('simone_predict1.xlsx', index_col=0)\n",
    "# df_ciro = pd.read_excel('ciro_predict1.xlsx', index_col=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
