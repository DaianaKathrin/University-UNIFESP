{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d977afc7",
   "metadata": {},
   "source": [
    "# Importando bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e57baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e77bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro_train = pd.read_excel('Bolsonaro_treino_sem_stop.xlsx')  \n",
    "df_lula_train = pd.read_excel('Lula_treino_sem_stop.xlsx') \n",
    "df_simone_train = pd.read_excel('Simone_treino_sem_stop.xlsx') \n",
    "df_ciro_train = pd.read_excel('Ciro_treino_sem_stop.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f914181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro = pd.read_excel('Bolsonaro_todos_sem_stop.xlsx', index_col=0)\n",
    "df_lula = pd.read_excel('Lula_todos_sem_stop.xlsx', index_col=0)\n",
    "df_simone = pd.read_excel('Simone_todos_sem_stop.xlsx', index_col=0)\n",
    "df_ciro = pd.read_excel('Ciro_todos_sem_stop.xlsx', index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6468928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lula_train = df_lula_train[df_lula_train['Sentimento']!=' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18fc2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag Of Words\n",
    "\n",
    "def Bag_of_words(df):\n",
    "    matrix = CountVectorizer()\n",
    "    text = []\n",
    "    for i in df.index:\n",
    "        text.append(\"\".join(df['novo_texto'][i]))\n",
    "    X = matrix.fit_transform(text)\n",
    "    return X, matrix\n",
    "\n",
    "def Bag_of_words_teste(df, matrix):\n",
    "    text = []\n",
    "    for i in df.index:\n",
    "        text.append(\"\".join(df['novo_texto'][i]))\n",
    "    X = matrix.transform(text)\n",
    "    return X\n",
    "\n",
    "def tfidf(df):\n",
    "    matrix = TfidfVectorizer()\n",
    "    text = []\n",
    "    for i in df.index:\n",
    "        text.append(\"\".join(df['novo_texto'][i]))\n",
    "    X = matrix.fit_transform(text)\n",
    "    return X, matrix\n",
    "\n",
    "def tfidf_teste(df, matrix):\n",
    "    text = []\n",
    "    for i in df.index:\n",
    "        text.append(\"\".join(df['novo_texto'][i]))\n",
    "    X = matrix.transform(text)\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464bd3fa",
   "metadata": {},
   "source": [
    "## Base treino bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab177c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bw_bolsonaro_train, bw_bolsonaro = Bag_of_words(df_bolsonaro_train)\n",
    "X_bw_lula_train, bw_lula = Bag_of_words(df_lula_train)\n",
    "X_bw_simone_train, bw_simone = Bag_of_words(df_simone_train)\n",
    "X_bw_ciro_train, bw_ciro = Bag_of_words(df_ciro_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f153217",
   "metadata": {},
   "source": [
    "## Base treino tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e295598",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_bolsonaro_train, tfidf_bolsonaro = tfidf(df_bolsonaro_train)\n",
    "X_tfidf_lula_train, tfidf_lula = tfidf(df_lula_train)\n",
    "X_tfidf_simone_train, tfidf_simone = tfidf(df_simone_train)\n",
    "X_tfidf_ciro_train, tfidf_ciro = tfidf(df_ciro_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28271fef",
   "metadata": {},
   "source": [
    "# Predict treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e810e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_bolsonaro_train = df_bolsonaro_train['Sentimento'].str.replace('p','1').replace('x','0').replace('n','-1').astype(int)\n",
    "Y_lula_train = df_lula_train['Sentimento'].str.replace('p','1').replace('x','0').replace('n','-1').astype(int)\n",
    "Y_simone_train = df_simone_train['Sentimento'].str.replace('p','1').replace('x','0').replace('n','-1').astype(int)\n",
    "Y_ciro_train = df_ciro_train['Sentimento'].str.replace('p','1').replace('x','0').replace('n','-1').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5469815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72038a02",
   "metadata": {},
   "source": [
    "## Bolsonaro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea48c83",
   "metadata": {},
   "source": [
    "### Bolsonaro - Arvore de Decisao - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd2f16ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8087876322213181"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bw_bolsonaro_train2 = X_bw_bolsonaro_train\n",
    "\n",
    "tree_bolsonaro_bw_test = tree.DecisionTreeClassifier()\n",
    "tree_X_bw_bolsonaro_train, tree_X_bw_bolsonaro_test, tree_Y_bw_bolsonaro_train, tree_Y_bw_bolsonaro_test = train_test_split(X_bw_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "tree_bolsonaro_bw_test = tree_bolsonaro_bw_test.fit(tree_X_bw_bolsonaro_train, tree_Y_bw_bolsonaro_train)\n",
    "\n",
    "score_tree_bw = tree_bolsonaro_bw_test.score(tree_X_bw_bolsonaro_test, tree_Y_bw_bolsonaro_test)\n",
    "tree_bolsonaro_bw = tree_bolsonaro_bw_test\n",
    "for i in range(0,100):\n",
    "    tree_bolsonaro_bw_test = tree.DecisionTreeClassifier()\n",
    "    tree_X_bw_bolsonaro_train, tree_X_bw_bolsonaro_test, tree_Y_bw_bolsonaro_train, tree_Y_bw_bolsonaro_test = train_test_split(X_bw_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "    tree_bolsonaro_bw_test = tree_bolsonaro_bw_test.fit(tree_X_bw_bolsonaro_train, tree_Y_bw_bolsonaro_train)\n",
    "    score_tree_bw_test = tree_bolsonaro_bw_test.score(tree_X_bw_bolsonaro_test, tree_Y_bw_bolsonaro_test)\n",
    "    if(score_tree_bw_test>score_tree_bw):\n",
    "        score_tree_bw = score_tree_bw_test\n",
    "        tree_bolsonaro_bw = tree_bolsonaro_bw_test\n",
    "score_tree_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dcfb39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([113610,  11239, 821589], dtype=int64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_bw_tree = tree_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_bw_tree = np.append(predict_bolsonaro_bw_tree, tree_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_bw_tree = np.append(predict_bolsonaro_bw_tree,tree_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:], bw_bolsonaro).toarray()))\n",
    "\n",
    "\n",
    "df_bolsonaro['predict_bw_ArvoreDeDecisao'] = predict_bolsonaro_bw_tree\n",
    "\n",
    "np.unique(predict_bolsonaro_bw_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdacb569",
   "metadata": {},
   "source": [
    "### Bolsonaro - Arvore de Decisao - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26b9dd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8144833197721725"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_bolsonaro_train2 = X_tfidf_bolsonaro_train\n",
    "\n",
    "tree_bolsonaro_tfidf_test = tree.DecisionTreeClassifier()\n",
    "tree_X_tfidf_bolsonaro_train, tree_X_tfidf_bolsonaro_test, tree_Y_tfidf_bolsonaro_train, tree_Y_tfidf_bolsonaro_test = train_test_split(X_tfidf_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "tree_bolsonaro_tfidf_test = tree_bolsonaro_tfidf_test.fit(tree_X_tfidf_bolsonaro_train, tree_Y_tfidf_bolsonaro_train)\n",
    "\n",
    "score_tree_tfidf = tree_bolsonaro_tfidf_test.score(tree_X_tfidf_bolsonaro_test, tree_Y_tfidf_bolsonaro_test)\n",
    "tree_bolsonaro_tfidf = tree_bolsonaro_tfidf_test\n",
    "for i in range(0,100):\n",
    "    tree_bolsonaro_tfidf_test = tree.DecisionTreeClassifier()\n",
    "    tree_X_tfidf_bolsonaro_train, tree_X_tfidf_bolsonaro_test, tree_Y_tfidf_bolsonaro_train, tree_Y_tfidf_bolsonaro_test = train_test_split(X_tfidf_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "    tree_bolsonaro_tfidf_test = tree_bolsonaro_tfidf_test.fit(tree_X_tfidf_bolsonaro_train, tree_Y_tfidf_bolsonaro_train)\n",
    "    score_tree_tfidf_test = tree_bolsonaro_tfidf_test.score(tree_X_tfidf_bolsonaro_test, tree_Y_tfidf_bolsonaro_test)\n",
    "    if(score_tree_tfidf_test>score_tree_tfidf):\n",
    "        score_tree_tfidf = score_tree_tfidf_test\n",
    "        tree_bolsonaro_tfidf = tree_bolsonaro_tfidf_test\n",
    "score_tree_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "077ceaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([153802,   9487, 783149], dtype=int64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_tfidf_tree = tree_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_tfidf_tree = np.append(predict_bolsonaro_tfidf_tree, tree_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_tfidf_tree = np.append(predict_bolsonaro_tfidf_tree,tree_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:], tfidf_bolsonaro).toarray()))\n",
    "\n",
    "\n",
    "df_bolsonaro['predict_tfidf_ArvoreDeDecisao'] = predict_bolsonaro_tfidf_tree\n",
    "\n",
    "np.unique(predict_bolsonaro_tfidf_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b2009f",
   "metadata": {},
   "source": [
    "### Bolsonaro - Naive Bayes - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "756c6fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6403580146460537"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_bolsonaro_bw_test = GaussianNB()\n",
    "GaussianNB_X_bw_bolsonaro_train, GaussianNB_X_bw_bolsonaro_test, GaussianNB_Y_bw_bolsonaro_train, GaussianNB_Y_bw_bolsonaro_test = train_test_split(X_bw_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "GaussianNB_bolsonaro_bw_test = GaussianNB_bolsonaro_bw_test.fit(GaussianNB_X_bw_bolsonaro_train.toarray(), GaussianNB_Y_bw_bolsonaro_train)\n",
    "\n",
    "score_GaussianNB_bw = GaussianNB_bolsonaro_bw_test.score(GaussianNB_X_bw_bolsonaro_test.toarray(), GaussianNB_Y_bw_bolsonaro_test)\n",
    "GaussianNB_bolsonaro_bw = GaussianNB_bolsonaro_bw_test\n",
    "for i in range(0,100):\n",
    "    GaussianNB_bolsonaro_bw_test = GaussianNB()\n",
    "    GaussianNB_X_bw_bolsonaro_train, GaussianNB_X_bw_bolsonaro_test, GaussianNB_Y_bw_bolsonaro_train, GaussianNB_Y_bw_bolsonaro_test = train_test_split(X_bw_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "    GaussianNB_bolsonaro_bw_test = GaussianNB_bolsonaro_bw_test.fit(GaussianNB_X_bw_bolsonaro_train.toarray(), GaussianNB_Y_bw_bolsonaro_train)\n",
    "    score_GaussianNB_bw_test = GaussianNB_bolsonaro_bw_test.score(GaussianNB_X_bw_bolsonaro_test.toarray(), GaussianNB_Y_bw_bolsonaro_test)\n",
    "    if(score_GaussianNB_bw_test>score_GaussianNB_bw):\n",
    "        score_GaussianNB_bw = score_GaussianNB_bw_test\n",
    "        GaussianNB_bolsonaro_bw = GaussianNB_bolsonaro_bw_test\n",
    "score_GaussianNB_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b76fd1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([299740,  14600, 632098], dtype=int64))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_bw_nb = GaussianNB_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_bw_nb = np.append(predict_bolsonaro_bw_nb, GaussianNB_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_bw_nb = np.append(predict_bolsonaro_bw_nb,GaussianNB_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:], bw_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_bw_NaiveBayes'] = predict_bolsonaro_bw_nb\n",
    "\n",
    "np.unique(predict_bolsonaro_bw_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7eb572",
   "metadata": {},
   "source": [
    "### Bolsonaro - Naive Bayes - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9802f64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.644426362896664"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_bolsonaro_tfidf_test = GaussianNB()\n",
    "GaussianNB_X_tfidf_bolsonaro_train, GaussianNB_X_tfidf_bolsonaro_test, GaussianNB_Y_tfidf_bolsonaro_train, GaussianNB_Y_tfidf_bolsonaro_test = train_test_split(X_tfidf_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "GaussianNB_bolsonaro_tfidf_test = GaussianNB_bolsonaro_tfidf_test.fit(GaussianNB_X_tfidf_bolsonaro_train.toarray(), GaussianNB_Y_tfidf_bolsonaro_train)\n",
    "\n",
    "score_GaussianNB_tfidf = GaussianNB_bolsonaro_tfidf_test.score(GaussianNB_X_tfidf_bolsonaro_test.toarray(), GaussianNB_Y_tfidf_bolsonaro_test)\n",
    "GaussianNB_bolsonaro_tfidf = GaussianNB_bolsonaro_tfidf_test\n",
    "for i in range(0,100):\n",
    "    GaussianNB_bolsonaro_tfidf_test = GaussianNB()\n",
    "    GaussianNB_X_tfidf_bolsonaro_train, GaussianNB_X_tfidf_bolsonaro_test, GaussianNB_Y_tfidf_bolsonaro_train, GaussianNB_Y_tfidf_bolsonaro_test = train_test_split(X_tfidf_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "    GaussianNB_bolsonaro_tfidf_test = GaussianNB_bolsonaro_tfidf_test.fit(GaussianNB_X_tfidf_bolsonaro_train.toarray(), GaussianNB_Y_tfidf_bolsonaro_train)\n",
    "    score_GaussianNB_tfidf_test = GaussianNB_bolsonaro_tfidf_test.score(GaussianNB_X_tfidf_bolsonaro_test.toarray(), GaussianNB_Y_tfidf_bolsonaro_test)\n",
    "    if(score_GaussianNB_tfidf_test>score_GaussianNB_tfidf):\n",
    "        score_GaussianNB_tfidf = score_GaussianNB_tfidf_test\n",
    "        GaussianNB_bolsonaro_tfidf = GaussianNB_bolsonaro_tfidf_test\n",
    "score_GaussianNB_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2fa062f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([295271,  17166, 634001], dtype=int64))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_tfidf_nb = GaussianNB_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_tfidf_nb = np.append(predict_bolsonaro_tfidf_nb, GaussianNB_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_tfidf_nb = np.append(predict_bolsonaro_tfidf_nb,GaussianNB_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:], tfidf_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_tfidf_NaiveBayes'] = predict_bolsonaro_tfidf_nb\n",
    "\n",
    "np.unique(predict_bolsonaro_tfidf_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c087da8",
   "metadata": {},
   "source": [
    "### Bolsonaro - Random Forest - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1b67e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8665581773799838"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_bolsonaro_bw_test = RandomForestClassifier()\n",
    "RandomForest_X_bw_bolsonaro_train, RandomForest_X_bw_bolsonaro_test, RandomForest_Y_bw_bolsonaro_train, RandomForest_Y_bw_bolsonaro_test = train_test_split(X_bw_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "RandomForest_bolsonaro_bw_test = RandomForest_bolsonaro_bw_test.fit(RandomForest_X_bw_bolsonaro_train.toarray(), RandomForest_Y_bw_bolsonaro_train)\n",
    "\n",
    "score_RandomForest_bw = RandomForest_bolsonaro_bw_test.score(RandomForest_X_bw_bolsonaro_test.toarray(), RandomForest_Y_bw_bolsonaro_test)\n",
    "RandomForest_bolsonaro_bw = RandomForest_bolsonaro_bw_test\n",
    "for i in range(0,100):\n",
    "    RandomForest_bolsonaro_bw_test = RandomForestClassifier()\n",
    "    RandomForest_X_bw_bolsonaro_train, RandomForest_X_bw_bolsonaro_test, RandomForest_Y_bw_bolsonaro_train, RandomForest_Y_bw_bolsonaro_test = train_test_split(X_bw_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "    RandomForest_bolsonaro_bw_test = RandomForest_bolsonaro_bw_test.fit(RandomForest_X_bw_bolsonaro_train.toarray(), RandomForest_Y_bw_bolsonaro_train)\n",
    "    score_RandomForest_bw_test = RandomForest_bolsonaro_bw_test.score(RandomForest_X_bw_bolsonaro_test.toarray(), RandomForest_Y_bw_bolsonaro_test)\n",
    "    if(score_RandomForest_bw_test>score_RandomForest_bw):\n",
    "        score_RandomForest_bw = score_RandomForest_bw_test\n",
    "        RandomForest_bolsonaro_bw = RandomForest_bolsonaro_bw_test\n",
    "score_RandomForest_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6174869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 22207,   2649, 921582], dtype=int64))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_bw_rf = RandomForest_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_bw_rf = np.append(predict_bolsonaro_bw_rf, RandomForest_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_bw_rf = np.append(predict_bolsonaro_bw_rf,RandomForest_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:], bw_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_bw_RandomForest'] = predict_bolsonaro_bw_rf\n",
    "\n",
    "np.unique(predict_bolsonaro_bw_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a2a87",
   "metadata": {},
   "source": [
    "### Bolsonaro - Random Forest - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "159352dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8722538649308381"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_bolsonaro_tfidf_test = RandomForestClassifier()\n",
    "RandomForest_X_tfidf_bolsonaro_train, RandomForest_X_tfidf_bolsonaro_test, RandomForest_Y_tfidf_bolsonaro_train, RandomForest_Y_tfidf_bolsonaro_test = train_test_split(X_tfidf_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "RandomForest_bolsonaro_tfidf_test = RandomForest_bolsonaro_tfidf_test.fit(RandomForest_X_tfidf_bolsonaro_train.toarray(), RandomForest_Y_tfidf_bolsonaro_train)\n",
    "\n",
    "score_RandomForest_tfidf = RandomForest_bolsonaro_tfidf_test.score(RandomForest_X_tfidf_bolsonaro_test.toarray(), RandomForest_Y_tfidf_bolsonaro_test)\n",
    "RandomForest_bolsonaro_tfidf = RandomForest_bolsonaro_tfidf_test\n",
    "for i in range(0,100):\n",
    "    RandomForest_bolsonaro_tfidf_test = RandomForestClassifier()\n",
    "    RandomForest_X_tfidf_bolsonaro_train, RandomForest_X_tfidf_bolsonaro_test, RandomForest_Y_tfidf_bolsonaro_train, RandomForest_Y_tfidf_bolsonaro_test = train_test_split(X_tfidf_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "    RandomForest_bolsonaro_tfidf_test = RandomForest_bolsonaro_tfidf_test.fit(RandomForest_X_tfidf_bolsonaro_train.toarray(), RandomForest_Y_tfidf_bolsonaro_train)\n",
    "    score_RandomForest_tfidf_test = RandomForest_bolsonaro_tfidf_test.score(RandomForest_X_tfidf_bolsonaro_test.toarray(), RandomForest_Y_tfidf_bolsonaro_test)\n",
    "    if(score_RandomForest_tfidf_test>score_RandomForest_tfidf):\n",
    "        score_RandomForest_tfidf = score_RandomForest_tfidf_test\n",
    "        RandomForest_bolsonaro_tfidf = RandomForest_bolsonaro_tfidf_test\n",
    "score_RandomForest_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d7eaeb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 20301,   3879, 922258], dtype=int64))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_tfidf_rf = RandomForest_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_tfidf_rf = np.append(predict_bolsonaro_tfidf_rf, RandomForest_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_tfidf_rf = np.append(predict_bolsonaro_tfidf_rf,RandomForest_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:], tfidf_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_tfidf_RandomForest'] = predict_bolsonaro_tfidf_rf\n",
    "\n",
    "np.unique(predict_bolsonaro_tfidf_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90533c53",
   "metadata": {},
   "source": [
    "### Bolsonaro - SVM - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "816c9f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8079739625711961"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_bolsonaro_bw_test = LinearSVC()\n",
    "svc_X_bw_bolsonaro_train, svc_X_bw_bolsonaro_test, svc_Y_bw_bolsonaro_train, svc_Y_bw_bolsonaro_test = train_test_split(X_bw_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "svc_bolsonaro_bw_test = svc_bolsonaro_bw_test.fit(svc_X_bw_bolsonaro_train.toarray(), svc_Y_bw_bolsonaro_train)\n",
    "\n",
    "score_svc_bw = svc_bolsonaro_bw_test.score(svc_X_bw_bolsonaro_test.toarray(), svc_Y_bw_bolsonaro_test)\n",
    "svc_bolsonaro_bw = svc_bolsonaro_bw_test\n",
    "for i in range(0,100):\n",
    "    svc_bolsonaro_bw_test = LinearSVC()\n",
    "    svc_X_bw_bolsonaro_train, svc_X_bw_bolsonaro_test, svc_Y_bw_bolsonaro_train, svc_Y_bw_bolsonaro_test = train_test_split(X_bw_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "    svc_bolsonaro_bw_test = svc_bolsonaro_bw_test.fit(svc_X_bw_bolsonaro_train.toarray(), svc_Y_bw_bolsonaro_train)\n",
    "    score_svc_bw_test = svc_bolsonaro_bw_test.score(svc_X_bw_bolsonaro_test.toarray(), svc_Y_bw_bolsonaro_test)\n",
    "    if(score_svc_bw_test>score_svc_bw):\n",
    "        score_svc_bw = score_svc_bw_test\n",
    "        svc_bolsonaro_bw = svc_bolsonaro_bw_test\n",
    "score_svc_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2440aa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([125054,   4192, 817192], dtype=int64))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_bw_svc = svc_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_bw_svc = np.append(predict_bolsonaro_bw_svc, svc_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_bw_svc = np.append(predict_bolsonaro_bw_svc,svc_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:], bw_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_bw_svc'] = predict_bolsonaro_bw_svc\n",
    "\n",
    "np.unique(predict_bolsonaro_bw_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2648b08f",
   "metadata": {},
   "source": [
    "### Bolsonaro - SVM - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2caa0798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8543531326281529"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_bolsonaro_tfidf_test = LinearSVC()\n",
    "svc_X_tfidf_bolsonaro_train, svc_X_tfidf_bolsonaro_test, svc_Y_tfidf_bolsonaro_train, svc_Y_tfidf_bolsonaro_test = train_test_split(X_tfidf_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "svc_bolsonaro_tfidf_test = svc_bolsonaro_tfidf_test.fit(svc_X_tfidf_bolsonaro_train.toarray(), svc_Y_tfidf_bolsonaro_train)\n",
    "\n",
    "score_svc_tfidf = svc_bolsonaro_tfidf_test.score(svc_X_tfidf_bolsonaro_test.toarray(), svc_Y_tfidf_bolsonaro_test)\n",
    "svc_bolsonaro_tfidf = svc_bolsonaro_tfidf_test\n",
    "for i in range(0,100):\n",
    "    svc_bolsonaro_tfidf_test = LinearSVC()\n",
    "    svc_X_tfidf_bolsonaro_train, svc_X_tfidf_bolsonaro_test, svc_Y_tfidf_bolsonaro_train, svc_Y_tfidf_bolsonaro_test = train_test_split(X_tfidf_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "    svc_bolsonaro_tfidf_test = svc_bolsonaro_tfidf_test.fit(svc_X_tfidf_bolsonaro_train.toarray(), svc_Y_tfidf_bolsonaro_train)\n",
    "    score_svc_tfidf_test = svc_bolsonaro_tfidf_test.score(svc_X_tfidf_bolsonaro_test.toarray(), svc_Y_tfidf_bolsonaro_test)\n",
    "    if(score_svc_tfidf_test>score_svc_tfidf):\n",
    "        score_svc_tfidf = score_svc_tfidf_test\n",
    "        svc_bolsonaro_tfidf = svc_bolsonaro_tfidf_test\n",
    "score_svc_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa1192dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 51153,    104, 895181], dtype=int64))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_tfidf_svc = svc_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_tfidf_svc = np.append(predict_bolsonaro_tfidf_svc, svc_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_tfidf_svc = np.append(predict_bolsonaro_tfidf_svc,svc_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:], tfidf_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_tfidf_svc'] = predict_bolsonaro_tfidf_svc\n",
    "\n",
    "np.unique(predict_bolsonaro_tfidf_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bf1c6d",
   "metadata": {},
   "source": [
    "### Bolsonaro - MLP - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25ef127e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7786818551668023"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bolsonaro_bw_test = MLPClassifier()\n",
    "mlp_X_bw_bolsonaro_train, mlp_X_bw_bolsonaro_test, mlp_Y_bw_bolsonaro_train, mlp_Y_bw_bolsonaro_test = train_test_split(X_bw_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "mlp_bolsonaro_bw_test = mlp_bolsonaro_bw_test.fit(mlp_X_bw_bolsonaro_train.toarray(), mlp_Y_bw_bolsonaro_train)\n",
    "\n",
    "score_mlp_bw = mlp_bolsonaro_bw_test.score(mlp_X_bw_bolsonaro_test.toarray(), mlp_Y_bw_bolsonaro_test)\n",
    "mlp_bolsonaro_bw = mlp_bolsonaro_bw_test\n",
    "for i in range(0,10):\n",
    "    mlp_bolsonaro_bw_test = MLPClassifier()\n",
    "    mlp_X_bw_bolsonaro_train, mlp_X_bw_bolsonaro_test, mlp_Y_bw_bolsonaro_train, mlp_Y_bw_bolsonaro_test = train_test_split(X_bw_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "    mlp_bolsonaro_bw_test = mlp_bolsonaro_bw_test.fit(mlp_X_bw_bolsonaro_train.toarray(), mlp_Y_bw_bolsonaro_train)\n",
    "    score_mlp_bw_test = mlp_bolsonaro_bw_test.score(mlp_X_bw_bolsonaro_test.toarray(), mlp_Y_bw_bolsonaro_test)\n",
    "    if(score_mlp_bw_test>score_mlp_bw):\n",
    "        score_mlp_bw = score_mlp_bw_test\n",
    "        mlp_bolsonaro_bw = mlp_bolsonaro_bw_test\n",
    "score_mlp_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "afc4d09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([151742,   4086, 790610], dtype=int64))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_bw_mlp = mlp_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_bw_mlp = np.append(predict_bolsonaro_bw_mlp, mlp_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:i], bw_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_bw_mlp = np.append(predict_bolsonaro_bw_mlp,mlp_bolsonaro_bw.predict(Bag_of_words_teste(df_bolsonaro[i1:], bw_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_bw_mlp'] = predict_bolsonaro_bw_mlp\n",
    "\n",
    "np.unique(predict_bolsonaro_bw_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cdc758",
   "metadata": {},
   "source": [
    "### Bolsonaro - MLP - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cdfe371f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.774613506916192"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bolsonaro_tfidf_test = MLPClassifier()\n",
    "mlp_X_tfidf_bolsonaro_train, mlp_X_tfidf_bolsonaro_test, mlp_Y_tfidf_bolsonaro_train, mlp_Y_tfidf_bolsonaro_test = train_test_split(X_tfidf_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "mlp_bolsonaro_tfidf_test = mlp_bolsonaro_tfidf_test.fit(mlp_X_tfidf_bolsonaro_train.toarray(), mlp_Y_tfidf_bolsonaro_train)\n",
    "\n",
    "score_mlp_tfidf = mlp_bolsonaro_tfidf_test.score(mlp_X_tfidf_bolsonaro_test.toarray(), mlp_Y_tfidf_bolsonaro_test)\n",
    "mlp_bolsonaro_tfidf = mlp_bolsonaro_tfidf_test\n",
    "for i in range(0,10):\n",
    "    mlp_bolsonaro_tfidf_test = MLPClassifier()\n",
    "    mlp_X_tfidf_bolsonaro_train, mlp_X_tfidf_bolsonaro_test, mlp_Y_tfidf_bolsonaro_train, mlp_Y_tfidf_bolsonaro_test = train_test_split(X_tfidf_bolsonaro_train2, Y_bolsonaro_train, test_size=0.2)\n",
    "    mlp_bolsonaro_tfidf_test = mlp_bolsonaro_tfidf_test.fit(mlp_X_tfidf_bolsonaro_train.toarray(), mlp_Y_tfidf_bolsonaro_train)\n",
    "    score_mlp_tfidf_test = mlp_bolsonaro_tfidf_test.score(mlp_X_tfidf_bolsonaro_test.toarray(), mlp_Y_tfidf_bolsonaro_test)\n",
    "    if(score_mlp_tfidf_test>score_mlp_tfidf):\n",
    "        score_mlp_tfidf = score_mlp_tfidf_test\n",
    "        mlp_bolsonaro_tfidf = mlp_bolsonaro_tfidf_test\n",
    "score_mlp_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e75bd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([144010,   1176, 801252], dtype=int64))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_bolsonaro),5000):\n",
    "    if (i==5000):\n",
    "        predict_bolsonaro_tfidf_mlp = mlp_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray())\n",
    "    else:\n",
    "        predict_bolsonaro_tfidf_mlp = np.append(predict_bolsonaro_tfidf_mlp, mlp_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:i], tfidf_bolsonaro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_bolsonaro_tfidf_mlp = np.append(predict_bolsonaro_tfidf_mlp,mlp_bolsonaro_tfidf.predict(tfidf_teste(df_bolsonaro[i1:], tfidf_bolsonaro).toarray()))\n",
    "\n",
    "df_bolsonaro['predict_tfidf_mlp'] = predict_bolsonaro_tfidf_mlp\n",
    "\n",
    "np.unique(predict_bolsonaro_tfidf_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b3295",
   "metadata": {},
   "source": [
    "# Lula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3979fdd8",
   "metadata": {},
   "source": [
    "### Lula - Arvore de Decisao - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b4542a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8434531185460553"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bw_lula_train2 = X_bw_lula_train\n",
    "\n",
    "tree_lula_bw_test = tree.DecisionTreeClassifier()\n",
    "tree_X_bw_lula_train, tree_X_bw_lula_test, tree_Y_bw_lula_train, tree_Y_bw_lula_test = train_test_split(X_bw_lula_train2, Y_lula_train, test_size=0.2)\n",
    "tree_lula_bw_test = tree_lula_bw_test.fit(tree_X_bw_lula_train, tree_Y_bw_lula_train)\n",
    "\n",
    "score_tree_bw = tree_lula_bw_test.score(tree_X_bw_lula_test, tree_Y_bw_lula_test)\n",
    "tree_lula_bw = tree_lula_bw_test\n",
    "for i in range(0,100):\n",
    "    tree_lula_bw_test = tree.DecisionTreeClassifier()\n",
    "    tree_X_bw_lula_train, tree_X_bw_lula_test, tree_Y_bw_lula_train, tree_Y_bw_lula_test = train_test_split(X_bw_lula_train2, Y_lula_train, test_size=0.2)\n",
    "    tree_lula_bw_test = tree_lula_bw_test.fit(tree_X_bw_lula_train, tree_Y_bw_lula_train)\n",
    "    score_tree_bw_test = tree_lula_bw_test.score(tree_X_bw_lula_test, tree_Y_bw_lula_test)\n",
    "    if(score_tree_bw_test>score_tree_bw):\n",
    "        score_tree_bw = score_tree_bw_test\n",
    "        tree_lula_bw = tree_lula_bw_test\n",
    "score_tree_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9a4d79bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 97322,   1909, 832499], dtype=int64))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_bw_tree = tree_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_bw_tree = np.append(predict_lula_bw_tree, tree_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_bw_tree = np.append(predict_lula_bw_tree,tree_lula_bw.predict(Bag_of_words_teste(df_lula[i1:], bw_lula).toarray()))\n",
    "\n",
    "\n",
    "df_lula['predict_bw_ArvoreDeDecisao'] = predict_lula_bw_tree\n",
    "\n",
    "np.unique(predict_lula_bw_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47713584",
   "metadata": {},
   "source": [
    "### Lula - Arvore de Decisao - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a7528298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8405617513424205"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_lula_train2 = X_tfidf_lula_train\n",
    "\n",
    "tree_lula_tfidf_test = tree.DecisionTreeClassifier()\n",
    "tree_X_tfidf_lula_train, tree_X_tfidf_lula_test, tree_Y_tfidf_lula_train, tree_Y_tfidf_lula_test = train_test_split(X_tfidf_lula_train2, Y_lula_train, test_size=0.2)\n",
    "tree_lula_tfidf_test = tree_lula_tfidf_test.fit(tree_X_tfidf_lula_train, tree_Y_tfidf_lula_train)\n",
    "\n",
    "score_tree_tfidf = tree_lula_tfidf_test.score(tree_X_tfidf_lula_test, tree_Y_tfidf_lula_test)\n",
    "tree_lula_tfidf = tree_lula_tfidf_test\n",
    "for i in range(0,100):\n",
    "    tree_lula_tfidf_test = tree.DecisionTreeClassifier()\n",
    "    tree_X_tfidf_lula_train, tree_X_tfidf_lula_test, tree_Y_tfidf_lula_train, tree_Y_tfidf_lula_test = train_test_split(X_tfidf_lula_train2, Y_lula_train, test_size=0.2)\n",
    "    tree_lula_tfidf_test = tree_lula_tfidf_test.fit(tree_X_tfidf_lula_train, tree_Y_tfidf_lula_train)\n",
    "    score_tree_tfidf_test = tree_lula_tfidf_test.score(tree_X_tfidf_lula_test, tree_Y_tfidf_lula_test)\n",
    "    if(score_tree_tfidf_test>score_tree_tfidf):\n",
    "        score_tree_tfidf = score_tree_tfidf_test\n",
    "        tree_lula_tfidf = tree_lula_tfidf_test\n",
    "score_tree_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "af353f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([134758,   1197, 795775], dtype=int64))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_tfidf_tree = tree_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_tfidf_tree = np.append(predict_lula_tfidf_tree, tree_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_tfidf_tree = np.append(predict_lula_tfidf_tree,tree_lula_tfidf.predict(tfidf_teste(df_lula[i1:], tfidf_lula).toarray()))\n",
    "\n",
    "\n",
    "df_lula['predict_tfidf_ArvoreDeDecisao'] = predict_lula_tfidf_tree\n",
    "\n",
    "np.unique(predict_lula_tfidf_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486ae1c8",
   "metadata": {},
   "source": [
    "### Lula - Naive Bayes - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c25b6a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5192069392812887"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_lula_bw_test = GaussianNB()\n",
    "GaussianNB_X_bw_lula_train, GaussianNB_X_bw_lula_test, GaussianNB_Y_bw_lula_train, GaussianNB_Y_bw_lula_test = train_test_split(X_bw_lula_train2, Y_lula_train, test_size=0.2)\n",
    "GaussianNB_lula_bw_test = GaussianNB_lula_bw_test.fit(GaussianNB_X_bw_lula_train.toarray(), GaussianNB_Y_bw_lula_train)\n",
    "\n",
    "score_GaussianNB_bw = GaussianNB_lula_bw_test.score(GaussianNB_X_bw_lula_test.toarray(), GaussianNB_Y_bw_lula_test)\n",
    "GaussianNB_lula_bw = GaussianNB_lula_bw_test\n",
    "for i in range(0,100):\n",
    "    GaussianNB_lula_bw_test = GaussianNB()\n",
    "    GaussianNB_X_bw_lula_train, GaussianNB_X_bw_lula_test, GaussianNB_Y_bw_lula_train, GaussianNB_Y_bw_lula_test = train_test_split(X_bw_lula_train2, Y_lula_train, test_size=0.2)\n",
    "    GaussianNB_lula_bw_test = GaussianNB_lula_bw_test.fit(GaussianNB_X_bw_lula_train.toarray(), GaussianNB_Y_bw_lula_train)\n",
    "    score_GaussianNB_bw_test = GaussianNB_lula_bw_test.score(GaussianNB_X_bw_lula_test.toarray(), GaussianNB_Y_bw_lula_test)\n",
    "    if(score_GaussianNB_bw_test>score_GaussianNB_bw):\n",
    "        score_GaussianNB_bw = score_GaussianNB_bw_test\n",
    "        GaussianNB_lula_bw = GaussianNB_lula_bw_test\n",
    "score_GaussianNB_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6eb08232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([392813,   5483, 533434], dtype=int64))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_bw_nb = GaussianNB_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_bw_nb = np.append(predict_lula_bw_nb, GaussianNB_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_bw_nb = np.append(predict_lula_bw_nb,GaussianNB_lula_bw.predict(Bag_of_words_teste(df_lula[i1:], bw_lula).toarray()))\n",
    "\n",
    "df_lula['predict_bw_NaiveBayes'] = predict_lula_bw_nb\n",
    "\n",
    "np.unique(predict_lula_bw_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76979985",
   "metadata": {},
   "source": [
    "### Lula - Naive Bayes - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a0565d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5365551425030979"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_lula_tfidf_test = GaussianNB()\n",
    "GaussianNB_X_tfidf_lula_train, GaussianNB_X_tfidf_lula_test, GaussianNB_Y_tfidf_lula_train, GaussianNB_Y_tfidf_lula_test = train_test_split(X_tfidf_lula_train2, Y_lula_train, test_size=0.2)\n",
    "GaussianNB_lula_tfidf_test = GaussianNB_lula_tfidf_test.fit(GaussianNB_X_tfidf_lula_train.toarray(), GaussianNB_Y_tfidf_lula_train)\n",
    "\n",
    "score_GaussianNB_tfidf = GaussianNB_lula_tfidf_test.score(GaussianNB_X_tfidf_lula_test.toarray(), GaussianNB_Y_tfidf_lula_test)\n",
    "GaussianNB_lula_tfidf = GaussianNB_lula_tfidf_test\n",
    "for i in range(0,100):\n",
    "    GaussianNB_lula_tfidf_test = GaussianNB()\n",
    "    GaussianNB_X_tfidf_lula_train, GaussianNB_X_tfidf_lula_test, GaussianNB_Y_tfidf_lula_train, GaussianNB_Y_tfidf_lula_test = train_test_split(X_tfidf_lula_train2, Y_lula_train, test_size=0.2)\n",
    "    GaussianNB_lula_tfidf_test = GaussianNB_lula_tfidf_test.fit(GaussianNB_X_tfidf_lula_train.toarray(), GaussianNB_Y_tfidf_lula_train)\n",
    "    score_GaussianNB_tfidf_test = GaussianNB_lula_tfidf_test.score(GaussianNB_X_tfidf_lula_test.toarray(), GaussianNB_Y_tfidf_lula_test)\n",
    "    if(score_GaussianNB_tfidf_test>score_GaussianNB_tfidf):\n",
    "        score_GaussianNB_tfidf = score_GaussianNB_tfidf_test\n",
    "        GaussianNB_lula_tfidf = GaussianNB_lula_tfidf_test\n",
    "score_GaussianNB_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8eda00ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([365118,   6326, 560286], dtype=int64))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_tfidf_nb = GaussianNB_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_tfidf_nb = np.append(predict_lula_tfidf_nb, GaussianNB_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_tfidf_nb = np.append(predict_lula_tfidf_nb,GaussianNB_lula_tfidf.predict(tfidf_teste(df_lula[i1:], tfidf_lula).toarray()))\n",
    "\n",
    "df_lula['predict_tfidf_NaiveBayes'] = predict_lula_tfidf_nb\n",
    "\n",
    "np.unique(predict_lula_tfidf_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dee4f",
   "metadata": {},
   "source": [
    "### Lula - Random Forest - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b90401f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8806278397356464"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_lula_bw_test = RandomForestClassifier()\n",
    "RandomForest_X_bw_lula_train, RandomForest_X_bw_lula_test, RandomForest_Y_bw_lula_train, RandomForest_Y_bw_lula_test = train_test_split(X_bw_lula_train2, Y_lula_train, test_size=0.2)\n",
    "RandomForest_lula_bw_test = RandomForest_lula_bw_test.fit(RandomForest_X_bw_lula_train.toarray(), RandomForest_Y_bw_lula_train)\n",
    "\n",
    "score_RandomForest_bw = RandomForest_lula_bw_test.score(RandomForest_X_bw_lula_test.toarray(), RandomForest_Y_bw_lula_test)\n",
    "RandomForest_lula_bw = RandomForest_lula_bw_test\n",
    "for i in range(0,100):\n",
    "    RandomForest_lula_bw_test = RandomForestClassifier()\n",
    "    RandomForest_X_bw_lula_train, RandomForest_X_bw_lula_test, RandomForest_Y_bw_lula_train, RandomForest_Y_bw_lula_test = train_test_split(X_bw_lula_train2, Y_lula_train, test_size=0.2)\n",
    "    RandomForest_lula_bw_test = RandomForest_lula_bw_test.fit(RandomForest_X_bw_lula_train.toarray(), RandomForest_Y_bw_lula_train)\n",
    "    score_RandomForest_bw_test = RandomForest_lula_bw_test.score(RandomForest_X_bw_lula_test.toarray(), RandomForest_Y_bw_lula_test)\n",
    "    if(score_RandomForest_bw_test>score_RandomForest_bw):\n",
    "        score_RandomForest_bw = score_RandomForest_bw_test\n",
    "        RandomForest_lula_bw = RandomForest_lula_bw_test\n",
    "score_RandomForest_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8bfae363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 18622,     26, 913082], dtype=int64))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_bw_rf = RandomForest_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_bw_rf = np.append(predict_lula_bw_rf, RandomForest_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_bw_rf = np.append(predict_lula_bw_rf,RandomForest_lula_bw.predict(Bag_of_words_teste(df_lula[i1:], bw_lula).toarray()))\n",
    "\n",
    "df_lula['predict_bw_RandomForest'] = predict_lula_bw_rf\n",
    "\n",
    "np.unique(predict_lula_bw_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550b54cb",
   "metadata": {},
   "source": [
    "### Lula - Random Forest - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f15963a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.889301941346551"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_lula_tfidf_test = RandomForestClassifier()\n",
    "RandomForest_X_tfidf_lula_train, RandomForest_X_tfidf_lula_test, RandomForest_Y_tfidf_lula_train, RandomForest_Y_tfidf_lula_test = train_test_split(X_tfidf_lula_train2, Y_lula_train, test_size=0.2)\n",
    "RandomForest_lula_tfidf_test = RandomForest_lula_tfidf_test.fit(RandomForest_X_tfidf_lula_train.toarray(), RandomForest_Y_tfidf_lula_train)\n",
    "\n",
    "score_RandomForest_tfidf = RandomForest_lula_tfidf_test.score(RandomForest_X_tfidf_lula_test.toarray(), RandomForest_Y_tfidf_lula_test)\n",
    "RandomForest_lula_tfidf = RandomForest_lula_tfidf_test\n",
    "for i in range(0,100):\n",
    "    RandomForest_lula_tfidf_test = RandomForestClassifier()\n",
    "    RandomForest_X_tfidf_lula_train, RandomForest_X_tfidf_lula_test, RandomForest_Y_tfidf_lula_train, RandomForest_Y_tfidf_lula_test = train_test_split(X_tfidf_lula_train2, Y_lula_train, test_size=0.2)\n",
    "    RandomForest_lula_tfidf_test = RandomForest_lula_tfidf_test.fit(RandomForest_X_tfidf_lula_train.toarray(), RandomForest_Y_tfidf_lula_train)\n",
    "    score_RandomForest_tfidf_test = RandomForest_lula_tfidf_test.score(RandomForest_X_tfidf_lula_test.toarray(), RandomForest_Y_tfidf_lula_test)\n",
    "    if(score_RandomForest_tfidf_test>score_RandomForest_tfidf):\n",
    "        score_RandomForest_tfidf = score_RandomForest_tfidf_test\n",
    "        RandomForest_lula_tfidf = RandomForest_lula_tfidf_test\n",
    "score_RandomForest_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cd640a70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 20315,     25, 911390], dtype=int64))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_tfidf_rf = RandomForest_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_tfidf_rf = np.append(predict_lula_tfidf_rf, RandomForest_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_tfidf_rf = np.append(predict_lula_tfidf_rf,RandomForest_lula_tfidf.predict(tfidf_teste(df_lula[i1:], tfidf_lula).toarray()))\n",
    "\n",
    "df_lula['predict_tfidf_RandomForest'] = predict_lula_tfidf_rf\n",
    "\n",
    "np.unique(predict_lula_tfidf_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0dc0d0",
   "metadata": {},
   "source": [
    "### lula - SVM - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e149aac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8451053283767038"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_lula_bw_test = LinearSVC()\n",
    "svc_X_bw_lula_train, svc_X_bw_lula_test, svc_Y_bw_lula_train, svc_Y_bw_lula_test = train_test_split(X_bw_lula_train2, Y_lula_train, test_size=0.2)\n",
    "svc_lula_bw_test = svc_lula_bw_test.fit(svc_X_bw_lula_train.toarray(), svc_Y_bw_lula_train)\n",
    "\n",
    "score_svc_bw = svc_lula_bw_test.score(svc_X_bw_lula_test.toarray(), svc_Y_bw_lula_test)\n",
    "svc_lula_bw = svc_lula_bw_test\n",
    "for i in range(0,100):\n",
    "    svc_lula_bw_test = LinearSVC()\n",
    "    svc_X_bw_lula_train, svc_X_bw_lula_test, svc_Y_bw_lula_train, svc_Y_bw_lula_test = train_test_split(X_bw_lula_train2, Y_lula_train, test_size=0.2)\n",
    "    svc_lula_bw_test = svc_lula_bw_test.fit(svc_X_bw_lula_train.toarray(), svc_Y_bw_lula_train)\n",
    "    score_svc_bw_test = svc_lula_bw_test.score(svc_X_bw_lula_test.toarray(), svc_Y_bw_lula_test)\n",
    "    if(score_svc_bw_test>score_svc_bw):\n",
    "        score_svc_bw = score_svc_bw_test\n",
    "        svc_lula_bw = svc_lula_bw_test\n",
    "score_svc_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "45d59fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([126996,    127, 804607], dtype=int64))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_bw_svc = svc_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_bw_svc = np.append(predict_lula_bw_svc, svc_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_bw_svc = np.append(predict_lula_bw_svc,svc_lula_bw.predict(Bag_of_words_teste(df_lula[i1:], bw_lula).toarray()))\n",
    "\n",
    "df_lula['predict_bw_svc'] = predict_lula_bw_svc\n",
    "\n",
    "np.unique(predict_lula_bw_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d180a",
   "metadata": {},
   "source": [
    "### lula - SVM - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "48031cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8793886823626601"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_lula_tfidf_test = LinearSVC()\n",
    "svc_X_tfidf_lula_train, svc_X_tfidf_lula_test, svc_Y_tfidf_lula_train, svc_Y_tfidf_lula_test = train_test_split(X_tfidf_lula_train2, Y_lula_train, test_size=0.2)\n",
    "svc_lula_tfidf_test = svc_lula_tfidf_test.fit(svc_X_tfidf_lula_train.toarray(), svc_Y_tfidf_lula_train)\n",
    "\n",
    "score_svc_tfidf = svc_lula_tfidf_test.score(svc_X_tfidf_lula_test.toarray(), svc_Y_tfidf_lula_test)\n",
    "svc_lula_tfidf = svc_lula_tfidf_test\n",
    "for i in range(0,100):\n",
    "    svc_lula_tfidf_test = LinearSVC()\n",
    "    svc_X_tfidf_lula_train, svc_X_tfidf_lula_test, svc_Y_tfidf_lula_train, svc_Y_tfidf_lula_test = train_test_split(X_tfidf_lula_train2, Y_lula_train, test_size=0.2)\n",
    "    svc_lula_tfidf_test = svc_lula_tfidf_test.fit(svc_X_tfidf_lula_train.toarray(), svc_Y_tfidf_lula_train)\n",
    "    score_svc_tfidf_test = svc_lula_tfidf_test.score(svc_X_tfidf_lula_test.toarray(), svc_Y_tfidf_lula_test)\n",
    "    if(score_svc_tfidf_test>score_svc_tfidf):\n",
    "        score_svc_tfidf = score_svc_tfidf_test\n",
    "        svc_lula_tfidf = svc_lula_tfidf_test\n",
    "score_svc_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3b03d307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 54700,     18, 877012], dtype=int64))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_tfidf_svc = svc_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_tfidf_svc = np.append(predict_lula_tfidf_svc, svc_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_tfidf_svc = np.append(predict_lula_tfidf_svc,svc_lula_tfidf.predict(tfidf_teste(df_lula[i1:], tfidf_lula).toarray()))\n",
    "\n",
    "df_lula['predict_tfidf_svc'] = predict_lula_tfidf_svc\n",
    "\n",
    "np.unique(predict_lula_tfidf_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d0c75",
   "metadata": {},
   "source": [
    "### Lula - MLP - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7f0b3ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8327137546468402"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_lula_bw_test = MLPClassifier()\n",
    "mlp_X_bw_lula_train, mlp_X_bw_lula_test, mlp_Y_bw_lula_train, mlp_Y_bw_lula_test = train_test_split(X_bw_lula_train2, Y_lula_train, test_size=0.2)\n",
    "mlp_lula_bw_test = mlp_lula_bw_test.fit(mlp_X_bw_lula_train.toarray(), mlp_Y_bw_lula_train)\n",
    "\n",
    "score_mlp_bw = mlp_lula_bw_test.score(mlp_X_bw_lula_test.toarray(), mlp_Y_bw_lula_test)\n",
    "mlp_lula_bw = mlp_lula_bw_test\n",
    "for i in range(0,10):\n",
    "    mlp_lula_bw_test = MLPClassifier()\n",
    "    mlp_X_bw_lula_train, mlp_X_bw_lula_test, mlp_Y_bw_lula_train, mlp_Y_bw_lula_test = train_test_split(X_bw_lula_train2, Y_lula_train, test_size=0.2)\n",
    "    mlp_lula_bw_test = mlp_lula_bw_test.fit(mlp_X_bw_lula_train.toarray(), mlp_Y_bw_lula_train)\n",
    "    score_mlp_bw_test = mlp_lula_bw_test.score(mlp_X_bw_lula_test.toarray(), mlp_Y_bw_lula_test)\n",
    "    if(score_mlp_bw_test>score_mlp_bw):\n",
    "        score_mlp_bw = score_mlp_bw_test\n",
    "        mlp_lula_bw = mlp_lula_bw_test\n",
    "score_mlp_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "701ced97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([103552,    311, 827867], dtype=int64))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_bw_mlp = mlp_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_bw_mlp = np.append(predict_lula_bw_mlp, mlp_lula_bw.predict(Bag_of_words_teste(df_lula[i1:i], bw_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_bw_mlp = np.append(predict_lula_bw_mlp,mlp_lula_bw.predict(Bag_of_words_teste(df_lula[i1:], bw_lula).toarray()))\n",
    "\n",
    "df_lula['predict_bw_mlp'] = predict_lula_bw_mlp\n",
    "\n",
    "np.unique(predict_lula_bw_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3916ac0b",
   "metadata": {},
   "source": [
    "### Lula - MLP - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6b923f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8446922759190417"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_lula_tfidf_test = MLPClassifier()\n",
    "mlp_X_tfidf_lula_train, mlp_X_tfidf_lula_test, mlp_Y_tfidf_lula_train, mlp_Y_tfidf_lula_test = train_test_split(X_tfidf_lula_train2, Y_lula_train, test_size=0.2)\n",
    "mlp_lula_tfidf_test = mlp_lula_tfidf_test.fit(mlp_X_tfidf_lula_train.toarray(), mlp_Y_tfidf_lula_train)\n",
    "\n",
    "score_mlp_tfidf = mlp_lula_tfidf_test.score(mlp_X_tfidf_lula_test.toarray(), mlp_Y_tfidf_lula_test)\n",
    "mlp_lula_tfidf = mlp_lula_tfidf_test\n",
    "for i in range(0,10):\n",
    "    mlp_lula_tfidf_test = MLPClassifier()\n",
    "    mlp_X_tfidf_lula_train, mlp_X_tfidf_lula_test, mlp_Y_tfidf_lula_train, mlp_Y_tfidf_lula_test = train_test_split(X_tfidf_lula_train2, Y_lula_train, test_size=0.2)\n",
    "    mlp_lula_tfidf_test = mlp_lula_tfidf_test.fit(mlp_X_tfidf_lula_train.toarray(), mlp_Y_tfidf_lula_train)\n",
    "    score_mlp_tfidf_test = mlp_lula_tfidf_test.score(mlp_X_tfidf_lula_test.toarray(), mlp_Y_tfidf_lula_test)\n",
    "    if(score_mlp_tfidf_test>score_mlp_tfidf):\n",
    "        score_mlp_tfidf = score_mlp_tfidf_test\n",
    "        mlp_lula_tfidf = mlp_lula_tfidf_test\n",
    "score_mlp_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "91986789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([117362,    141, 814227], dtype=int64))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_lula),5000):\n",
    "    if (i==5000):\n",
    "        predict_lula_tfidf_mlp = mlp_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray())\n",
    "    else:\n",
    "        predict_lula_tfidf_mlp = np.append(predict_lula_tfidf_mlp, mlp_lula_tfidf.predict(tfidf_teste(df_lula[i1:i], tfidf_lula).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_lula_tfidf_mlp = np.append(predict_lula_tfidf_mlp,mlp_lula_tfidf.predict(tfidf_teste(df_lula[i1:], tfidf_lula).toarray()))\n",
    "\n",
    "df_lula['predict_tfidf_mlp'] = predict_lula_tfidf_mlp\n",
    "\n",
    "np.unique(predict_lula_tfidf_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db094735",
   "metadata": {},
   "source": [
    "# Simone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ad64c",
   "metadata": {},
   "source": [
    "### Simone - Arvore de Decisao - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0de6efd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7083333333333334"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bw_simone_train2 = X_bw_simone_train\n",
    "\n",
    "tree_simone_bw_test = tree.DecisionTreeClassifier()\n",
    "tree_X_bw_simone_train, tree_X_bw_simone_test, tree_Y_bw_simone_train, tree_Y_bw_simone_test = train_test_split(X_bw_simone_train2, Y_simone_train, test_size=0.2)\n",
    "tree_simone_bw_test = tree_simone_bw_test.fit(tree_X_bw_simone_train, tree_Y_bw_simone_train)\n",
    "\n",
    "score_tree_bw = tree_simone_bw_test.score(tree_X_bw_simone_test, tree_Y_bw_simone_test)\n",
    "tree_simone_bw = tree_simone_bw_test\n",
    "for i in range(0,100):\n",
    "    tree_simone_bw_test = tree.DecisionTreeClassifier()\n",
    "    tree_X_bw_simone_train, tree_X_bw_simone_test, tree_Y_bw_simone_train, tree_Y_bw_simone_test = train_test_split(X_bw_simone_train2, Y_simone_train, test_size=0.2)\n",
    "    tree_simone_bw_test = tree_simone_bw_test.fit(tree_X_bw_simone_train, tree_Y_bw_simone_train)\n",
    "    score_tree_bw_test = tree_simone_bw_test.score(tree_X_bw_simone_test, tree_Y_bw_simone_test)\n",
    "    if(score_tree_bw_test>score_tree_bw):\n",
    "        score_tree_bw = score_tree_bw_test\n",
    "        tree_simone_bw = tree_simone_bw_test\n",
    "score_tree_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1a36189b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 7945, 78065, 45152], dtype=int64))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_bw_tree = tree_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_bw_tree = np.append(predict_simone_bw_tree, tree_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_bw_tree = np.append(predict_simone_bw_tree,tree_simone_bw.predict(Bag_of_words_teste(df_simone[i1:], bw_simone).toarray()))\n",
    "\n",
    "\n",
    "df_simone['predict_bw_ArvoreDeDecisao'] = predict_simone_bw_tree\n",
    "\n",
    "np.unique(predict_simone_bw_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f4a8ef",
   "metadata": {},
   "source": [
    "### Simone - Arvore de Decisao - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43ad13f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7708333333333334"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_simone_train2 = X_tfidf_simone_train\n",
    "\n",
    "tree_simone_tfidf_test = tree.DecisionTreeClassifier()\n",
    "tree_X_tfidf_simone_train, tree_X_tfidf_simone_test, tree_Y_tfidf_simone_train, tree_Y_tfidf_simone_test = train_test_split(X_tfidf_simone_train2, Y_simone_train, test_size=0.2)\n",
    "tree_simone_tfidf_test = tree_simone_tfidf_test.fit(tree_X_tfidf_simone_train, tree_Y_tfidf_simone_train)\n",
    "\n",
    "score_tree_tfidf = tree_simone_tfidf_test.score(tree_X_tfidf_simone_test, tree_Y_tfidf_simone_test)\n",
    "tree_simone_tfidf = tree_simone_tfidf_test\n",
    "for i in range(0,100):\n",
    "    tree_simone_tfidf_test = tree.DecisionTreeClassifier()\n",
    "    tree_X_tfidf_simone_train, tree_X_tfidf_simone_test, tree_Y_tfidf_simone_train, tree_Y_tfidf_simone_test = train_test_split(X_tfidf_simone_train2, Y_simone_train, test_size=0.2)\n",
    "    tree_simone_tfidf_test = tree_simone_tfidf_test.fit(tree_X_tfidf_simone_train, tree_Y_tfidf_simone_train)\n",
    "    score_tree_tfidf_test = tree_simone_tfidf_test.score(tree_X_tfidf_simone_test, tree_Y_tfidf_simone_test)\n",
    "    if(score_tree_tfidf_test>score_tree_tfidf):\n",
    "        score_tree_tfidf = score_tree_tfidf_test\n",
    "        tree_simone_tfidf = tree_simone_tfidf_test\n",
    "score_tree_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f72b876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 5426, 66730, 59006], dtype=int64))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_tfidf_tree = tree_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_tfidf_tree = np.append(predict_simone_tfidf_tree, tree_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_tfidf_tree = np.append(predict_simone_tfidf_tree,tree_simone_tfidf.predict(tfidf_teste(df_simone[i1:], tfidf_simone).toarray()))\n",
    "\n",
    "\n",
    "df_simone['predict_tfidf_ArvoreDeDecisao'] = predict_simone_tfidf_tree\n",
    "\n",
    "np.unique(predict_simone_tfidf_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f934ee36",
   "metadata": {},
   "source": [
    "### Simone - Naive Bayes - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "55d83565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7291666666666666"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_simone_bw_test = GaussianNB()\n",
    "GaussianNB_X_bw_simone_train, GaussianNB_X_bw_simone_test, GaussianNB_Y_bw_simone_train, GaussianNB_Y_bw_simone_test = train_test_split(X_bw_simone_train2, Y_simone_train, test_size=0.2)\n",
    "GaussianNB_simone_bw_test = GaussianNB_simone_bw_test.fit(GaussianNB_X_bw_simone_train.toarray(), GaussianNB_Y_bw_simone_train)\n",
    "\n",
    "score_GaussianNB_bw = GaussianNB_simone_bw_test.score(GaussianNB_X_bw_simone_test.toarray(), GaussianNB_Y_bw_simone_test)\n",
    "GaussianNB_simone_bw = GaussianNB_simone_bw_test\n",
    "for i in range(0,100):\n",
    "    GaussianNB_simone_bw_test = GaussianNB()\n",
    "    GaussianNB_X_bw_simone_train, GaussianNB_X_bw_simone_test, GaussianNB_Y_bw_simone_train, GaussianNB_Y_bw_simone_test = train_test_split(X_bw_simone_train2, Y_simone_train, test_size=0.2)\n",
    "    GaussianNB_simone_bw_test = GaussianNB_simone_bw_test.fit(GaussianNB_X_bw_simone_train.toarray(), GaussianNB_Y_bw_simone_train)\n",
    "    score_GaussianNB_bw_test = GaussianNB_simone_bw_test.score(GaussianNB_X_bw_simone_test.toarray(), GaussianNB_Y_bw_simone_test)\n",
    "    if(score_GaussianNB_bw_test>score_GaussianNB_bw):\n",
    "        score_GaussianNB_bw = score_GaussianNB_bw_test\n",
    "        GaussianNB_simone_bw = GaussianNB_simone_bw_test\n",
    "score_GaussianNB_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c14c77b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([11932, 68318, 50912], dtype=int64))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_bw_nb = GaussianNB_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_bw_nb = np.append(predict_simone_bw_nb, GaussianNB_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_bw_nb = np.append(predict_simone_bw_nb,GaussianNB_simone_bw.predict(Bag_of_words_teste(df_simone[i1:], bw_simone).toarray()))\n",
    "\n",
    "df_simone['predict_bw_NaiveBayes'] = predict_simone_bw_nb\n",
    "\n",
    "np.unique(predict_simone_bw_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713a8608",
   "metadata": {},
   "source": [
    "### Simone - Naive Bayes - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6eeea615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_simone_tfidf_test = GaussianNB()\n",
    "GaussianNB_X_tfidf_simone_train, GaussianNB_X_tfidf_simone_test, GaussianNB_Y_tfidf_simone_train, GaussianNB_Y_tfidf_simone_test = train_test_split(X_tfidf_simone_train2, Y_simone_train, test_size=0.2)\n",
    "GaussianNB_simone_tfidf_test = GaussianNB_simone_tfidf_test.fit(GaussianNB_X_tfidf_simone_train.toarray(), GaussianNB_Y_tfidf_simone_train)\n",
    "\n",
    "score_GaussianNB_tfidf = GaussianNB_simone_tfidf_test.score(GaussianNB_X_tfidf_simone_test.toarray(), GaussianNB_Y_tfidf_simone_test)\n",
    "GaussianNB_simone_tfidf = GaussianNB_simone_tfidf_test\n",
    "for i in range(0,100):\n",
    "    GaussianNB_simone_tfidf_test = GaussianNB()\n",
    "    GaussianNB_X_tfidf_simone_train, GaussianNB_X_tfidf_simone_test, GaussianNB_Y_tfidf_simone_train, GaussianNB_Y_tfidf_simone_test = train_test_split(X_tfidf_simone_train2, Y_simone_train, test_size=0.2)\n",
    "    GaussianNB_simone_tfidf_test = GaussianNB_simone_tfidf_test.fit(GaussianNB_X_tfidf_simone_train.toarray(), GaussianNB_Y_tfidf_simone_train)\n",
    "    score_GaussianNB_tfidf_test = GaussianNB_simone_tfidf_test.score(GaussianNB_X_tfidf_simone_test.toarray(), GaussianNB_Y_tfidf_simone_test)\n",
    "    if(score_GaussianNB_tfidf_test>score_GaussianNB_tfidf):\n",
    "        score_GaussianNB_tfidf = score_GaussianNB_tfidf_test\n",
    "        GaussianNB_simone_tfidf = GaussianNB_simone_tfidf_test\n",
    "score_GaussianNB_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "45b52514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([13229, 55522, 62411], dtype=int64))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_tfidf_nb = GaussianNB_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_tfidf_nb = np.append(predict_simone_tfidf_nb, GaussianNB_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_tfidf_nb = np.append(predict_simone_tfidf_nb,GaussianNB_simone_tfidf.predict(tfidf_teste(df_simone[i1:], tfidf_simone).toarray()))\n",
    "\n",
    "df_simone['predict_tfidf_NaiveBayes'] = predict_simone_tfidf_nb\n",
    "\n",
    "np.unique(predict_simone_tfidf_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e64f12",
   "metadata": {},
   "source": [
    "### Simone - Random Forest - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "31aaf2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7708333333333334"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_simone_bw_test = RandomForestClassifier()\n",
    "RandomForest_X_bw_simone_train, RandomForest_X_bw_simone_test, RandomForest_Y_bw_simone_train, RandomForest_Y_bw_simone_test = train_test_split(X_bw_simone_train2, Y_simone_train, test_size=0.2)\n",
    "RandomForest_simone_bw_test = RandomForest_simone_bw_test.fit(RandomForest_X_bw_simone_train.toarray(), RandomForest_Y_bw_simone_train)\n",
    "\n",
    "score_RandomForest_bw = RandomForest_simone_bw_test.score(RandomForest_X_bw_simone_test.toarray(), RandomForest_Y_bw_simone_test)\n",
    "RandomForest_simone_bw = RandomForest_simone_bw_test\n",
    "for i in range(0,100):\n",
    "    RandomForest_simone_bw_test = RandomForestClassifier()\n",
    "    RandomForest_X_bw_simone_train, RandomForest_X_bw_simone_test, RandomForest_Y_bw_simone_train, RandomForest_Y_bw_simone_test = train_test_split(X_bw_simone_train2, Y_simone_train, test_size=0.2)\n",
    "    RandomForest_simone_bw_test = RandomForest_simone_bw_test.fit(RandomForest_X_bw_simone_train.toarray(), RandomForest_Y_bw_simone_train)\n",
    "    score_RandomForest_bw_test = RandomForest_simone_bw_test.score(RandomForest_X_bw_simone_test.toarray(), RandomForest_Y_bw_simone_test)\n",
    "    if(score_RandomForest_bw_test>score_RandomForest_bw):\n",
    "        score_RandomForest_bw = score_RandomForest_bw_test\n",
    "        RandomForest_simone_bw = RandomForest_simone_bw_test\n",
    "score_RandomForest_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d2c6dd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([  102, 43078, 87982], dtype=int64))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_bw_rf = RandomForest_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_bw_rf = np.append(predict_simone_bw_rf, RandomForest_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_bw_rf = np.append(predict_simone_bw_rf,RandomForest_simone_bw.predict(Bag_of_words_teste(df_simone[i1:], bw_simone).toarray()))\n",
    "\n",
    "df_simone['predict_bw_RandomForest'] = predict_simone_bw_rf\n",
    "\n",
    "np.unique(predict_simone_bw_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e45eb2",
   "metadata": {},
   "source": [
    "### Simone - Random Forest - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "01ad477f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_simone_tfidf_test = RandomForestClassifier()\n",
    "RandomForest_X_tfidf_simone_train, RandomForest_X_tfidf_simone_test, RandomForest_Y_tfidf_simone_train, RandomForest_Y_tfidf_simone_test = train_test_split(X_tfidf_simone_train2, Y_simone_train, test_size=0.2)\n",
    "RandomForest_simone_tfidf_test = RandomForest_simone_tfidf_test.fit(RandomForest_X_tfidf_simone_train.toarray(), RandomForest_Y_tfidf_simone_train)\n",
    "\n",
    "score_RandomForest_tfidf = RandomForest_simone_tfidf_test.score(RandomForest_X_tfidf_simone_test.toarray(), RandomForest_Y_tfidf_simone_test)\n",
    "RandomForest_simone_tfidf = RandomForest_simone_tfidf_test\n",
    "for i in range(0,100):\n",
    "    RandomForest_simone_tfidf_test = RandomForestClassifier()\n",
    "    RandomForest_X_tfidf_simone_train, RandomForest_X_tfidf_simone_test, RandomForest_Y_tfidf_simone_train, RandomForest_Y_tfidf_simone_test = train_test_split(X_tfidf_simone_train2, Y_simone_train, test_size=0.2)\n",
    "    RandomForest_simone_tfidf_test = RandomForest_simone_tfidf_test.fit(RandomForest_X_tfidf_simone_train.toarray(), RandomForest_Y_tfidf_simone_train)\n",
    "    score_RandomForest_tfidf_test = RandomForest_simone_tfidf_test.score(RandomForest_X_tfidf_simone_test.toarray(), RandomForest_Y_tfidf_simone_test)\n",
    "    if(score_RandomForest_tfidf_test>score_RandomForest_tfidf):\n",
    "        score_RandomForest_tfidf = score_RandomForest_tfidf_test\n",
    "        RandomForest_simone_tfidf = RandomForest_simone_tfidf_test\n",
    "score_RandomForest_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bf01ad28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([  111, 59182, 71869], dtype=int64))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_tfidf_rf = RandomForest_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_tfidf_rf = np.append(predict_simone_tfidf_rf, RandomForest_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_tfidf_rf = np.append(predict_simone_tfidf_rf,RandomForest_simone_tfidf.predict(tfidf_teste(df_simone[i1:], tfidf_simone).toarray()))\n",
    "\n",
    "df_simone['predict_tfidf_RandomForest'] = predict_simone_tfidf_rf\n",
    "\n",
    "np.unique(predict_simone_tfidf_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5aa5d4",
   "metadata": {},
   "source": [
    "### Simone - SVM - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4d91ccc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_simone_bw_test = LinearSVC()\n",
    "svc_X_bw_simone_train, svc_X_bw_simone_test, svc_Y_bw_simone_train, svc_Y_bw_simone_test = train_test_split(X_bw_simone_train2, Y_simone_train, test_size=0.2)\n",
    "svc_simone_bw_test = svc_simone_bw_test.fit(svc_X_bw_simone_train.toarray(), svc_Y_bw_simone_train)\n",
    "\n",
    "score_svc_bw = svc_simone_bw_test.score(svc_X_bw_simone_test.toarray(), svc_Y_bw_simone_test)\n",
    "svc_simone_bw = svc_simone_bw_test\n",
    "for i in range(0,100):\n",
    "    svc_simone_bw_test = LinearSVC()\n",
    "    svc_X_bw_simone_train, svc_X_bw_simone_test, svc_Y_bw_simone_train, svc_Y_bw_simone_test = train_test_split(X_bw_simone_train2, Y_simone_train, test_size=0.2)\n",
    "    svc_simone_bw_test = svc_simone_bw_test.fit(svc_X_bw_simone_train.toarray(), svc_Y_bw_simone_train)\n",
    "    score_svc_bw_test = svc_simone_bw_test.score(svc_X_bw_simone_test.toarray(), svc_Y_bw_simone_test)\n",
    "    if(score_svc_bw_test>score_svc_bw):\n",
    "        score_svc_bw = score_svc_bw_test\n",
    "        svc_simone_bw = svc_simone_bw_test\n",
    "score_svc_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3e133598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 6125, 62159, 62878], dtype=int64))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_bw_svc = svc_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_bw_svc = np.append(predict_simone_bw_svc, svc_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_bw_svc = np.append(predict_simone_bw_svc,svc_simone_bw.predict(Bag_of_words_teste(df_simone[i1:], bw_simone).toarray()))\n",
    "\n",
    "df_simone['predict_bw_svc'] = predict_simone_bw_svc\n",
    "\n",
    "np.unique(predict_simone_bw_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6dce97",
   "metadata": {},
   "source": [
    "### Simone - SVM - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "eaa57f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_simone_tfidf_test = LinearSVC()\n",
    "svc_X_tfidf_simone_train, svc_X_tfidf_simone_test, svc_Y_tfidf_simone_train, svc_Y_tfidf_simone_test = train_test_split(X_tfidf_simone_train2, Y_simone_train, test_size=0.2)\n",
    "svc_simone_tfidf_test = svc_simone_tfidf_test.fit(svc_X_tfidf_simone_train.toarray(), svc_Y_tfidf_simone_train)\n",
    "\n",
    "score_svc_tfidf = svc_simone_tfidf_test.score(svc_X_tfidf_simone_test.toarray(), svc_Y_tfidf_simone_test)\n",
    "svc_simone_tfidf = svc_simone_tfidf_test\n",
    "for i in range(0,100):\n",
    "    svc_simone_tfidf_test = LinearSVC()\n",
    "    svc_X_tfidf_simone_train, svc_X_tfidf_simone_test, svc_Y_tfidf_simone_train, svc_Y_tfidf_simone_test = train_test_split(X_tfidf_simone_train2, Y_simone_train, test_size=0.2)\n",
    "    svc_simone_tfidf_test = svc_simone_tfidf_test.fit(svc_X_tfidf_simone_train.toarray(), svc_Y_tfidf_simone_train)\n",
    "    score_svc_tfidf_test = svc_simone_tfidf_test.score(svc_X_tfidf_simone_test.toarray(), svc_Y_tfidf_simone_test)\n",
    "    if(score_svc_tfidf_test>score_svc_tfidf):\n",
    "        score_svc_tfidf = score_svc_tfidf_test\n",
    "        svc_simone_tfidf = svc_simone_tfidf_test\n",
    "score_svc_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "84772651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 9325, 59014, 62823], dtype=int64))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_tfidf_svc = svc_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_tfidf_svc = np.append(predict_simone_tfidf_svc, svc_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_tfidf_svc = np.append(predict_simone_tfidf_svc,svc_simone_tfidf.predict(tfidf_teste(df_simone[i1:], tfidf_simone).toarray()))\n",
    "\n",
    "df_simone['predict_tfidf_svc'] = predict_simone_tfidf_svc\n",
    "\n",
    "np.unique(predict_simone_tfidf_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069f365",
   "metadata": {},
   "source": [
    "### Simone - MLP - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "76b62e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_simone_bw_test = MLPClassifier()\n",
    "mlp_X_bw_simone_train, mlp_X_bw_simone_test, mlp_Y_bw_simone_train, mlp_Y_bw_simone_test = train_test_split(X_bw_simone_train2, Y_simone_train, test_size=0.2)\n",
    "mlp_simone_bw_test = mlp_simone_bw_test.fit(mlp_X_bw_simone_train.toarray(), mlp_Y_bw_simone_train)\n",
    "\n",
    "score_mlp_bw = mlp_simone_bw_test.score(mlp_X_bw_simone_test.toarray(), mlp_Y_bw_simone_test)\n",
    "mlp_simone_bw = mlp_simone_bw_test\n",
    "for i in range(0,10):\n",
    "    mlp_simone_bw_test = MLPClassifier()\n",
    "    mlp_X_bw_simone_train, mlp_X_bw_simone_test, mlp_Y_bw_simone_train, mlp_Y_bw_simone_test = train_test_split(X_bw_simone_train2, Y_simone_train, test_size=0.2)\n",
    "    mlp_simone_bw_test = mlp_simone_bw_test.fit(mlp_X_bw_simone_train.toarray(), mlp_Y_bw_simone_train)\n",
    "    score_mlp_bw_test = mlp_simone_bw_test.score(mlp_X_bw_simone_test.toarray(), mlp_Y_bw_simone_test)\n",
    "    if(score_mlp_bw_test>score_mlp_bw):\n",
    "        score_mlp_bw = score_mlp_bw_test\n",
    "        mlp_simone_bw = mlp_simone_bw_test\n",
    "score_mlp_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "11607d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 2388, 65680, 63094], dtype=int64))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_bw_mlp = mlp_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_bw_mlp = np.append(predict_simone_bw_mlp, mlp_simone_bw.predict(Bag_of_words_teste(df_simone[i1:i], bw_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_bw_mlp = np.append(predict_simone_bw_mlp,mlp_simone_bw.predict(Bag_of_words_teste(df_simone[i1:], bw_simone).toarray()))\n",
    "\n",
    "df_simone['predict_bw_mlp'] = predict_simone_bw_mlp\n",
    "df_simone['predict_bw_mlp2'] = predict_simone_bw_mlp\n",
    "\n",
    "np.unique(predict_simone_bw_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55494fc2",
   "metadata": {},
   "source": [
    "### Simone - MLP - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e187fac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7083333333333334"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_simone_tfidf_test = MLPClassifier()\n",
    "mlp_X_tfidf_simone_train, mlp_X_tfidf_simone_test, mlp_Y_tfidf_simone_train, mlp_Y_tfidf_simone_test = train_test_split(X_tfidf_simone_train2, Y_simone_train, test_size=0.2)\n",
    "mlp_simone_tfidf_test = mlp_simone_tfidf_test.fit(mlp_X_tfidf_simone_train.toarray(), mlp_Y_tfidf_simone_train)\n",
    "\n",
    "score_mlp_tfidf = mlp_simone_tfidf_test.score(mlp_X_tfidf_simone_test.toarray(), mlp_Y_tfidf_simone_test)\n",
    "mlp_simone_tfidf = mlp_simone_tfidf_test\n",
    "for i in range(0,10):\n",
    "    mlp_simone_tfidf_test = MLPClassifier()\n",
    "    mlp_X_tfidf_simone_train, mlp_X_tfidf_simone_test, mlp_Y_tfidf_simone_train, mlp_Y_tfidf_simone_test = train_test_split(X_tfidf_simone_train2, Y_simone_train, test_size=0.2)\n",
    "    mlp_simone_tfidf_test = mlp_simone_tfidf_test.fit(mlp_X_tfidf_simone_train.toarray(), mlp_Y_tfidf_simone_train)\n",
    "    score_mlp_tfidf_test = mlp_simone_tfidf_test.score(mlp_X_tfidf_simone_test.toarray(), mlp_Y_tfidf_simone_test)\n",
    "    if(score_mlp_tfidf_test>score_mlp_tfidf):\n",
    "        score_mlp_tfidf = score_mlp_tfidf_test\n",
    "        mlp_simone_tfidf = mlp_simone_tfidf_test\n",
    "score_mlp_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "789cf937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([ 9972, 52189, 69001], dtype=int64))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_simone),5000):\n",
    "    if (i==5000):\n",
    "        predict_simone_tfidf_mlp = mlp_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray())\n",
    "    else:\n",
    "        predict_simone_tfidf_mlp = np.append(predict_simone_tfidf_mlp, mlp_simone_tfidf.predict(tfidf_teste(df_simone[i1:i], tfidf_simone).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_simone_tfidf_mlp = np.append(predict_simone_tfidf_mlp,mlp_simone_tfidf.predict(tfidf_teste(df_simone[i1:], tfidf_simone).toarray()))\n",
    "\n",
    "df_simone['predict_tfidf_mlp'] = predict_simone_tfidf_mlp\n",
    "df_simone['predict_tfidf_mlp2'] = predict_simone_tfidf_mlp\n",
    "\n",
    "np.unique(predict_simone_tfidf_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e720fd",
   "metadata": {},
   "source": [
    "# Ciro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beb534f",
   "metadata": {},
   "source": [
    "### Ciro - Arvore de Decisao - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0a317ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992636229749632"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bw_ciro_train2 = X_bw_ciro_train\n",
    "\n",
    "tree_ciro_bw_test = tree.DecisionTreeClassifier()\n",
    "tree_X_bw_ciro_train, tree_X_bw_ciro_test, tree_Y_bw_ciro_train, tree_Y_bw_ciro_test = train_test_split(X_bw_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "tree_ciro_bw_test = tree_ciro_bw_test.fit(tree_X_bw_ciro_train, tree_Y_bw_ciro_train)\n",
    "\n",
    "score_tree_bw = tree_ciro_bw_test.score(tree_X_bw_ciro_test, tree_Y_bw_ciro_test)\n",
    "tree_ciro_bw = tree_ciro_bw_test\n",
    "for i in range(0,100):\n",
    "    tree_ciro_bw_test = tree.DecisionTreeClassifier()\n",
    "    tree_X_bw_ciro_train, tree_X_bw_ciro_test, tree_Y_bw_ciro_train, tree_Y_bw_ciro_test = train_test_split(X_bw_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "    tree_ciro_bw_test = tree_ciro_bw_test.fit(tree_X_bw_ciro_train, tree_Y_bw_ciro_train)\n",
    "    score_tree_bw_test = tree_ciro_bw_test.score(tree_X_bw_ciro_test, tree_Y_bw_ciro_test)\n",
    "    if(score_tree_bw_test>score_tree_bw):\n",
    "        score_tree_bw = score_tree_bw_test\n",
    "        tree_ciro_bw = tree_ciro_bw_test\n",
    "score_tree_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b428b700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([   370,     74, 497622], dtype=int64))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_bw_tree = tree_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_bw_tree = np.append(predict_ciro_bw_tree, tree_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_bw_tree = np.append(predict_ciro_bw_tree,tree_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:], bw_ciro).toarray()))\n",
    "\n",
    "\n",
    "df_ciro['predict_bw_ArvoreDeDecisao'] = predict_ciro_bw_tree\n",
    "\n",
    "np.unique(predict_ciro_bw_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad56845",
   "metadata": {},
   "source": [
    "### Ciro - Arvore de Decisao - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a26c1c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985272459499264"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_ciro_train2 = X_tfidf_ciro_train\n",
    "\n",
    "tree_ciro_tfidf_test = tree.DecisionTreeClassifier()\n",
    "tree_X_tfidf_ciro_train, tree_X_tfidf_ciro_test, tree_Y_tfidf_ciro_train, tree_Y_tfidf_ciro_test = train_test_split(X_tfidf_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "tree_ciro_tfidf_test = tree_ciro_tfidf_test.fit(tree_X_tfidf_ciro_train, tree_Y_tfidf_ciro_train)\n",
    "\n",
    "score_tree_tfidf = tree_ciro_tfidf_test.score(tree_X_tfidf_ciro_test, tree_Y_tfidf_ciro_test)\n",
    "tree_ciro_tfidf = tree_ciro_tfidf_test\n",
    "for i in range(0,100):\n",
    "    tree_ciro_tfidf_test = tree.DecisionTreeClassifier()\n",
    "    tree_X_tfidf_ciro_train, tree_X_tfidf_ciro_test, tree_Y_tfidf_ciro_train, tree_Y_tfidf_ciro_test = train_test_split(X_tfidf_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "    tree_ciro_tfidf_test = tree_ciro_tfidf_test.fit(tree_X_tfidf_ciro_train, tree_Y_tfidf_ciro_train)\n",
    "    score_tree_tfidf_test = tree_ciro_tfidf_test.score(tree_X_tfidf_ciro_test, tree_Y_tfidf_ciro_test)\n",
    "    if(score_tree_tfidf_test>score_tree_tfidf):\n",
    "        score_tree_tfidf = score_tree_tfidf_test\n",
    "        tree_ciro_tfidf = tree_ciro_tfidf_test\n",
    "score_tree_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9e3ddade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([   667,   1109, 496290], dtype=int64))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_tfidf_tree = tree_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_tfidf_tree = np.append(predict_ciro_tfidf_tree, tree_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_tfidf_tree = np.append(predict_ciro_tfidf_tree,tree_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:], tfidf_ciro).toarray()))\n",
    "\n",
    "\n",
    "df_ciro['predict_tfidf_ArvoreDeDecisao'] = predict_ciro_tfidf_tree\n",
    "\n",
    "np.unique(predict_ciro_tfidf_tree, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac990958",
   "metadata": {},
   "source": [
    "### Ciro - Naive Bayes - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1039c570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9852724594992637"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_ciro_bw_test = GaussianNB()\n",
    "GaussianNB_X_bw_ciro_train, GaussianNB_X_bw_ciro_test, GaussianNB_Y_bw_ciro_train, GaussianNB_Y_bw_ciro_test = train_test_split(X_bw_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "GaussianNB_ciro_bw_test = GaussianNB_ciro_bw_test.fit(GaussianNB_X_bw_ciro_train.toarray(), GaussianNB_Y_bw_ciro_train)\n",
    "\n",
    "score_GaussianNB_bw = GaussianNB_ciro_bw_test.score(GaussianNB_X_bw_ciro_test.toarray(), GaussianNB_Y_bw_ciro_test)\n",
    "GaussianNB_ciro_bw = GaussianNB_ciro_bw_test\n",
    "for i in range(0,100):\n",
    "    GaussianNB_ciro_bw_test = GaussianNB()\n",
    "    GaussianNB_X_bw_ciro_train, GaussianNB_X_bw_ciro_test, GaussianNB_Y_bw_ciro_train, GaussianNB_Y_bw_ciro_test = train_test_split(X_bw_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "    GaussianNB_ciro_bw_test = GaussianNB_ciro_bw_test.fit(GaussianNB_X_bw_ciro_train.toarray(), GaussianNB_Y_bw_ciro_train)\n",
    "    score_GaussianNB_bw_test = GaussianNB_ciro_bw_test.score(GaussianNB_X_bw_ciro_test.toarray(), GaussianNB_Y_bw_ciro_test)\n",
    "    if(score_GaussianNB_bw_test>score_GaussianNB_bw):\n",
    "        score_GaussianNB_bw = score_GaussianNB_bw_test\n",
    "        GaussianNB_ciro_bw = GaussianNB_ciro_bw_test\n",
    "score_GaussianNB_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "298d9a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([  4282,   3316, 490468], dtype=int64))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_bw_nb = GaussianNB_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_bw_nb = np.append(predict_ciro_bw_nb, GaussianNB_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_bw_nb = np.append(predict_ciro_bw_nb,GaussianNB_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:], bw_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_bw_NaiveBayes'] = predict_ciro_bw_nb\n",
    "\n",
    "np.unique(predict_ciro_bw_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f03aad2",
   "metadata": {},
   "source": [
    "### Ciro - Naive Bayes - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0fbc84a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9845360824742269"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB_ciro_tfidf_test = GaussianNB()\n",
    "GaussianNB_X_tfidf_ciro_train, GaussianNB_X_tfidf_ciro_test, GaussianNB_Y_tfidf_ciro_train, GaussianNB_Y_tfidf_ciro_test = train_test_split(X_tfidf_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "GaussianNB_ciro_tfidf_test = GaussianNB_ciro_tfidf_test.fit(GaussianNB_X_tfidf_ciro_train.toarray(), GaussianNB_Y_tfidf_ciro_train)\n",
    "\n",
    "score_GaussianNB_tfidf = GaussianNB_ciro_tfidf_test.score(GaussianNB_X_tfidf_ciro_test.toarray(), GaussianNB_Y_tfidf_ciro_test)\n",
    "GaussianNB_ciro_tfidf = GaussianNB_ciro_tfidf_test\n",
    "for i in range(0,100):\n",
    "    GaussianNB_ciro_tfidf_test = GaussianNB()\n",
    "    GaussianNB_X_tfidf_ciro_train, GaussianNB_X_tfidf_ciro_test, GaussianNB_Y_tfidf_ciro_train, GaussianNB_Y_tfidf_ciro_test = train_test_split(X_tfidf_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "    GaussianNB_ciro_tfidf_test = GaussianNB_ciro_tfidf_test.fit(GaussianNB_X_tfidf_ciro_train.toarray(), GaussianNB_Y_tfidf_ciro_train)\n",
    "    score_GaussianNB_tfidf_test = GaussianNB_ciro_tfidf_test.score(GaussianNB_X_tfidf_ciro_test.toarray(), GaussianNB_Y_tfidf_ciro_test)\n",
    "    if(score_GaussianNB_tfidf_test>score_GaussianNB_tfidf):\n",
    "        score_GaussianNB_tfidf = score_GaussianNB_tfidf_test\n",
    "        GaussianNB_ciro_tfidf = GaussianNB_ciro_tfidf_test\n",
    "score_GaussianNB_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c0b92dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([  4672,   1782, 491612], dtype=int64))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_tfidf_nb = GaussianNB_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_tfidf_nb = np.append(predict_ciro_tfidf_nb, GaussianNB_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_tfidf_nb = np.append(predict_ciro_tfidf_nb,GaussianNB_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:], tfidf_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_tfidf_NaiveBayes'] = predict_ciro_tfidf_nb\n",
    "\n",
    "np.unique(predict_ciro_tfidf_nb, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84080ded",
   "metadata": {},
   "source": [
    "### Ciro - Random Forest - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c5b089d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992636229749632"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_ciro_bw_test = RandomForestClassifier()\n",
    "RandomForest_X_bw_ciro_train, RandomForest_X_bw_ciro_test, RandomForest_Y_bw_ciro_train, RandomForest_Y_bw_ciro_test = train_test_split(X_bw_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "RandomForest_ciro_bw_test = RandomForest_ciro_bw_test.fit(RandomForest_X_bw_ciro_train.toarray(), RandomForest_Y_bw_ciro_train)\n",
    "\n",
    "score_RandomForest_bw = RandomForest_ciro_bw_test.score(RandomForest_X_bw_ciro_test.toarray(), RandomForest_Y_bw_ciro_test)\n",
    "RandomForest_ciro_bw = RandomForest_ciro_bw_test\n",
    "for i in range(0,100):\n",
    "    RandomForest_ciro_bw_test = RandomForestClassifier()\n",
    "    RandomForest_X_bw_ciro_train, RandomForest_X_bw_ciro_test, RandomForest_Y_bw_ciro_train, RandomForest_Y_bw_ciro_test = train_test_split(X_bw_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "    RandomForest_ciro_bw_test = RandomForest_ciro_bw_test.fit(RandomForest_X_bw_ciro_train.toarray(), RandomForest_Y_bw_ciro_train)\n",
    "    score_RandomForest_bw_test = RandomForest_ciro_bw_test.score(RandomForest_X_bw_ciro_test.toarray(), RandomForest_Y_bw_ciro_test)\n",
    "    if(score_RandomForest_bw_test>score_RandomForest_bw):\n",
    "        score_RandomForest_bw = score_RandomForest_bw_test\n",
    "        RandomForest_ciro_bw = RandomForest_ciro_bw_test\n",
    "score_RandomForest_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "07583215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([    12,     11, 498043], dtype=int64))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_bw_rf = RandomForest_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_bw_rf = np.append(predict_ciro_bw_rf, RandomForest_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_bw_rf = np.append(predict_ciro_bw_rf,RandomForest_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:], bw_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_bw_RandomForest'] = predict_ciro_bw_rf\n",
    "\n",
    "np.unique(predict_ciro_bw_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682ac138",
   "metadata": {},
   "source": [
    "### Ciro - Random Forest - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "08ec4371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992636229749632"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_ciro_tfidf_test = RandomForestClassifier()\n",
    "RandomForest_X_tfidf_ciro_train, RandomForest_X_tfidf_ciro_test, RandomForest_Y_tfidf_ciro_train, RandomForest_Y_tfidf_ciro_test = train_test_split(X_tfidf_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "RandomForest_ciro_tfidf_test = RandomForest_ciro_tfidf_test.fit(RandomForest_X_tfidf_ciro_train.toarray(), RandomForest_Y_tfidf_ciro_train)\n",
    "\n",
    "score_RandomForest_tfidf = RandomForest_ciro_tfidf_test.score(RandomForest_X_tfidf_ciro_test.toarray(), RandomForest_Y_tfidf_ciro_test)\n",
    "RandomForest_ciro_tfidf = RandomForest_ciro_tfidf_test\n",
    "for i in range(0,100):\n",
    "    RandomForest_ciro_tfidf_test = RandomForestClassifier()\n",
    "    RandomForest_X_tfidf_ciro_train, RandomForest_X_tfidf_ciro_test, RandomForest_Y_tfidf_ciro_train, RandomForest_Y_tfidf_ciro_test = train_test_split(X_tfidf_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "    RandomForest_ciro_tfidf_test = RandomForest_ciro_tfidf_test.fit(RandomForest_X_tfidf_ciro_train.toarray(), RandomForest_Y_tfidf_ciro_train)\n",
    "    score_RandomForest_tfidf_test = RandomForest_ciro_tfidf_test.score(RandomForest_X_tfidf_ciro_test.toarray(), RandomForest_Y_tfidf_ciro_test)\n",
    "    if(score_RandomForest_tfidf_test>score_RandomForest_tfidf):\n",
    "        score_RandomForest_tfidf = score_RandomForest_tfidf_test\n",
    "        RandomForest_ciro_tfidf = RandomForest_ciro_tfidf_test\n",
    "score_RandomForest_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8e823047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([    12,     14, 498040], dtype=int64))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_tfidf_rf = RandomForest_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_tfidf_rf = np.append(predict_ciro_tfidf_rf, RandomForest_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_tfidf_rf = np.append(predict_ciro_tfidf_rf,RandomForest_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:], tfidf_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_tfidf_RandomForest'] = predict_ciro_tfidf_rf\n",
    "\n",
    "np.unique(predict_ciro_tfidf_rf, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15fd085",
   "metadata": {},
   "source": [
    "### Ciro - SVM - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c67acaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\daian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9985272459499264"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_ciro_bw_test = LinearSVC()\n",
    "svc_X_bw_ciro_train, svc_X_bw_ciro_test, svc_Y_bw_ciro_train, svc_Y_bw_ciro_test = train_test_split(X_bw_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "svc_ciro_bw_test = svc_ciro_bw_test.fit(svc_X_bw_ciro_train.toarray(), svc_Y_bw_ciro_train)\n",
    "\n",
    "score_svc_bw = svc_ciro_bw_test.score(svc_X_bw_ciro_test.toarray(), svc_Y_bw_ciro_test)\n",
    "svc_ciro_bw = svc_ciro_bw_test\n",
    "for i in range(0,100):\n",
    "    svc_ciro_bw_test = LinearSVC()\n",
    "    svc_X_bw_ciro_train, svc_X_bw_ciro_test, svc_Y_bw_ciro_train, svc_Y_bw_ciro_test = train_test_split(X_bw_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "    svc_ciro_bw_test = svc_ciro_bw_test.fit(svc_X_bw_ciro_train.toarray(), svc_Y_bw_ciro_train)\n",
    "    score_svc_bw_test = svc_ciro_bw_test.score(svc_X_bw_ciro_test.toarray(), svc_Y_bw_ciro_test)\n",
    "    if(score_svc_bw_test>score_svc_bw):\n",
    "        score_svc_bw = score_svc_bw_test\n",
    "        svc_ciro_bw = svc_ciro_bw_test\n",
    "score_svc_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d292996b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([    75,     21, 497970], dtype=int64))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_bw_svc = svc_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_bw_svc = np.append(predict_ciro_bw_svc, svc_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_bw_svc = np.append(predict_ciro_bw_svc,svc_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:], bw_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_bw_svc'] = predict_ciro_bw_svc\n",
    "\n",
    "np.unique(predict_ciro_bw_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0fa02e",
   "metadata": {},
   "source": [
    "### Ciro - SVM - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8c6ce0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985272459499264"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_ciro_tfidf_test = LinearSVC()\n",
    "svc_X_tfidf_ciro_train, svc_X_tfidf_ciro_test, svc_Y_tfidf_ciro_train, svc_Y_tfidf_ciro_test = train_test_split(X_tfidf_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "svc_ciro_tfidf_test = svc_ciro_tfidf_test.fit(svc_X_tfidf_ciro_train.toarray(), svc_Y_tfidf_ciro_train)\n",
    "\n",
    "score_svc_tfidf = svc_ciro_tfidf_test.score(svc_X_tfidf_ciro_test.toarray(), svc_Y_tfidf_ciro_test)\n",
    "svc_ciro_tfidf = svc_ciro_tfidf_test\n",
    "for i in range(0,100):\n",
    "    svc_ciro_tfidf_test = LinearSVC()\n",
    "    svc_X_tfidf_ciro_train, svc_X_tfidf_ciro_test, svc_Y_tfidf_ciro_train, svc_Y_tfidf_ciro_test = train_test_split(X_tfidf_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "    svc_ciro_tfidf_test = svc_ciro_tfidf_test.fit(svc_X_tfidf_ciro_train.toarray(), svc_Y_tfidf_ciro_train)\n",
    "    score_svc_tfidf_test = svc_ciro_tfidf_test.score(svc_X_tfidf_ciro_test.toarray(), svc_Y_tfidf_ciro_test)\n",
    "    if(score_svc_tfidf_test>score_svc_tfidf):\n",
    "        score_svc_tfidf = score_svc_tfidf_test\n",
    "        svc_ciro_tfidf = svc_ciro_tfidf_test\n",
    "score_svc_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e2d77fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([    17,      8, 498041], dtype=int64))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_tfidf_svc = svc_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_tfidf_svc = np.append(predict_ciro_tfidf_svc, svc_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_tfidf_svc = np.append(predict_ciro_tfidf_svc,svc_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:], tfidf_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_tfidf_svc'] = predict_ciro_tfidf_svc\n",
    "\n",
    "np.unique(predict_ciro_tfidf_svc, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e38f4",
   "metadata": {},
   "source": [
    "### Ciro - MLP - bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6daba2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985272459499264"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_ciro_bw_test = MLPClassifier()\n",
    "mlp_X_bw_ciro_train, mlp_X_bw_ciro_test, mlp_Y_bw_ciro_train, mlp_Y_bw_ciro_test = train_test_split(X_bw_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "mlp_ciro_bw_test = mlp_ciro_bw_test.fit(mlp_X_bw_ciro_train.toarray(), mlp_Y_bw_ciro_train)\n",
    "\n",
    "score_mlp_bw = mlp_ciro_bw_test.score(mlp_X_bw_ciro_test.toarray(), mlp_Y_bw_ciro_test)\n",
    "mlp_ciro_bw = mlp_ciro_bw_test\n",
    "for i in range(0,10):\n",
    "    mlp_ciro_bw_test = MLPClassifier()\n",
    "    mlp_X_bw_ciro_train, mlp_X_bw_ciro_test, mlp_Y_bw_ciro_train, mlp_Y_bw_ciro_test = train_test_split(X_bw_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "    mlp_ciro_bw_test = mlp_ciro_bw_test.fit(mlp_X_bw_ciro_train.toarray(), mlp_Y_bw_ciro_train)\n",
    "    score_mlp_bw_test = mlp_ciro_bw_test.score(mlp_X_bw_ciro_test.toarray(), mlp_Y_bw_ciro_test)\n",
    "    if(score_mlp_bw_test>score_mlp_bw):\n",
    "        score_mlp_bw = score_mlp_bw_test\n",
    "        mlp_ciro_bw = mlp_ciro_bw_test\n",
    "score_mlp_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "095aee16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([    17,     14, 498035], dtype=int64))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_bw_mlp = mlp_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_bw_mlp = np.append(predict_ciro_bw_mlp, mlp_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:i], bw_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_bw_mlp = np.append(predict_ciro_bw_mlp,mlp_ciro_bw.predict(Bag_of_words_teste(df_ciro[i1:], bw_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_bw_mlp'] = predict_ciro_bw_mlp\n",
    "df_ciro['predict_bw_mlp2'] = predict_ciro_bw_mlp\n",
    "\n",
    "np.unique(predict_ciro_bw_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c6f382",
   "metadata": {},
   "source": [
    "### Ciro - MLP - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8a461d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992636229749632"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_ciro_tfidf_test = MLPClassifier()\n",
    "mlp_X_tfidf_ciro_train, mlp_X_tfidf_ciro_test, mlp_Y_tfidf_ciro_train, mlp_Y_tfidf_ciro_test = train_test_split(X_tfidf_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "mlp_ciro_tfidf_test = mlp_ciro_tfidf_test.fit(mlp_X_tfidf_ciro_train.toarray(), mlp_Y_tfidf_ciro_train)\n",
    "\n",
    "score_mlp_tfidf = mlp_ciro_tfidf_test.score(mlp_X_tfidf_ciro_test.toarray(), mlp_Y_tfidf_ciro_test)\n",
    "mlp_ciro_tfidf = mlp_ciro_tfidf_test\n",
    "for i in range(0,10):\n",
    "    mlp_ciro_tfidf_test = MLPClassifier()\n",
    "    mlp_X_tfidf_ciro_train, mlp_X_tfidf_ciro_test, mlp_Y_tfidf_ciro_train, mlp_Y_tfidf_ciro_test = train_test_split(X_tfidf_ciro_train2, Y_ciro_train, test_size=0.2)\n",
    "    mlp_ciro_tfidf_test = mlp_ciro_tfidf_test.fit(mlp_X_tfidf_ciro_train.toarray(), mlp_Y_tfidf_ciro_train)\n",
    "    score_mlp_tfidf_test = mlp_ciro_tfidf_test.score(mlp_X_tfidf_ciro_test.toarray(), mlp_Y_tfidf_ciro_test)\n",
    "    if(score_mlp_tfidf_test>score_mlp_tfidf):\n",
    "        score_mlp_tfidf = score_mlp_tfidf_test\n",
    "        mlp_ciro_tfidf = mlp_ciro_tfidf_test\n",
    "score_mlp_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0a57c9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([    22,     14, 498030], dtype=int64))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=0\n",
    "for i in range(5000,len(df_ciro),5000):\n",
    "    if (i==5000):\n",
    "        predict_ciro_tfidf_mlp = mlp_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray())\n",
    "    else:\n",
    "        predict_ciro_tfidf_mlp = np.append(predict_ciro_tfidf_mlp, mlp_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:i], tfidf_ciro).toarray()))\n",
    "    i1=i\n",
    "\n",
    "predict_ciro_tfidf_mlp = np.append(predict_ciro_tfidf_mlp,mlp_ciro_tfidf.predict(tfidf_teste(df_ciro[i1:], tfidf_ciro).toarray()))\n",
    "\n",
    "df_ciro['predict_tfidf_mlp'] = predict_ciro_tfidf_mlp\n",
    "df_ciro['predict_tfidf_mlp2'] = predict_ciro_tfidf_mlp\n",
    "\n",
    "np.unique(predict_ciro_tfidf_mlp, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2f967f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro.to_excel('bolsonaro_predict2.xlsx')\n",
    "df_lula.to_excel('lula_predict2.xlsx')\n",
    "df_simone.to_excel('simone_predict2.xlsx')\n",
    "df_ciro.to_excel('ciro_predict2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "58714574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VotacaoPredict(df):\n",
    "    for i in df.index:\n",
    "        pos=0\n",
    "        neu=0\n",
    "        neg=0\n",
    "        for j in ['predict_tfidf_mlp','predict_bw_mlp',\n",
    "                  'predict_tfidf_svc','predict_bw_svc',\n",
    "                 'predict_tfidf_RandomForest','predict_bw_RandomForest',\n",
    "                 'predict_tfidf_NaiveBayes','predict_bw_NaiveBayes',\n",
    "                 'predict_tfidf_ArvoreDeDecisao','predict_bw_ArvoreDeDecisao']:\n",
    "            if (df.loc[i,j]==1):\n",
    "                pos+=1\n",
    "            elif (df.loc[i,j]==0):\n",
    "                neu+=1    \n",
    "            else:\n",
    "                neg+=1\n",
    "            \n",
    "        \n",
    "        if((neu>=neg)& (neu>=pos)):\n",
    "            df.loc[i,'VotacaoPredict_norm'] = 0\n",
    "        elif((neg>=pos)& (neg>=neu)):\n",
    "            df.loc[i,'VotacaoPredict_norm'] = -1\n",
    "        else:\n",
    "            df.loc[i,'VotacaoPredict_norm'] = 1     \n",
    "    print(df['VotacaoPredict_norm'].value_counts())        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "133c0e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0    732672\n",
      "-1.0    209248\n",
      " 0.0      4518\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n",
      " 1.0    877772\n",
      "-1.0     65899\n",
      " 0.0      2767\n",
      "Name: VotacaoPredict_norm, dtype: int64\n",
      " 1.0    741160\n",
      "-1.0    190450\n",
      " 0.0       120\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n",
      " 1.0    874608\n",
      "-1.0     57094\n",
      " 0.0        28\n",
      "Name: VotacaoPredict_norm, dtype: int64\n",
      " 0.0    84932\n",
      " 1.0    39112\n",
      "-1.0     7118\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n",
      " 1.0    65021\n",
      " 0.0    63718\n",
      "-1.0     2423\n",
      "Name: VotacaoPredict_norm, dtype: int64\n",
      " 1.0    498011\n",
      "-1.0        36\n",
      " 0.0        19\n",
      "Name: VotacaoPredict_ajust, dtype: int64\n",
      " 1.0    498033\n",
      "-1.0        20\n",
      " 0.0        13\n",
      "Name: VotacaoPredict_norm, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_bolsonaro_predict2 = VotacaoPredict(df_bolsonaro)\n",
    "df_lula_predict2 = VotacaoPredict(df_lula)\n",
    "df_simone_predict2 = VotacaoPredict(df_simone)\n",
    "df_ciro_predict2 = VotacaoPredict(df_ciro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "830d47e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0    826633\n",
      "-1.0    116816\n",
      " 0.0      2989\n",
      "Name: VotacaoPredict_norm, dtype: int64\n",
      " 1.0    842343\n",
      "-1.0     89340\n",
      " 0.0        47\n",
      "Name: VotacaoPredict_norm, dtype: int64\n",
      " 0.0    73303\n",
      " 1.0    52873\n",
      "-1.0     4986\n",
      "Name: VotacaoPredict_norm, dtype: int64\n",
      " 1.0    498033\n",
      "-1.0        20\n",
      " 0.0        13\n",
      "Name: VotacaoPredict_norm, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_bolsonaro_predict['VotacaoPredict_norm'].value_counts())\n",
    "print(df_lula_predict['VotacaoPredict_norm'].value_counts())\n",
    "print(df_simone_predict['VotacaoPredict_norm'].value_counts())\n",
    "print(df_ciro_predict['VotacaoPredict_norm'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "756de764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro_predict2.to_excel('bolsonaro_resultado_treinoTeste.xlsx')\n",
    "df_lula_predict2.to_excel('lula_resultado_treinoTeste.xlsx')\n",
    "df_simone_predict2.to_excel('simone_resultado_treinoTeste.xlsx')\n",
    "df_ciro_predict2.to_excel('ciro_resultado_treinoTeste.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
