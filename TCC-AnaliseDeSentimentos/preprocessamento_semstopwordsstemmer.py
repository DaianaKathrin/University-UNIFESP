# -*- coding: utf-8 -*-
"""PreProcessamento_semStopWordsStemmer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19YLjbUSd5TsO1S1QLPRctXlEQ8ktl_U8
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import nltk
from nltk.corpus import stopwords
import re
from nltk.stem import PorterStemmer
from unidecode import unidecode
import itertools
import nltk
nltk.download('rslp')
stemmer = nltk.stem.RSLPStemmer()
stemmer.stem("copiar")
# nltk.download("stopwords")
# nltk.download("punkt")
# nltk.download("tagsets")
# nltk.download("wordnet")
# nltk.download("averaged_perceptron_tagger")
# nltk.download("maxent_ne_chunker")
# nltk.download("words")
# nltk.download()

df_antigo = pd.read_csv('extracoes/outros/extracao_1.csv', index_col=0)
df_antigo = df_antigo.append(pd.read_csv('extracoes/outros/extracao_2.csv', index_col=0))
df_antigo = df_antigo.append(pd.read_csv('extracoes/outros/extracao_total.csv', index_col=0))
df_antigo

df_antigo = df_antigo.drop_duplicates()
df_antigo

df_bolsonaro = pd.read_csv('extracoes/extracao_28_09_bolsonaro.csv', index_col=0)


df_bolsonaro = df_bolsonaro.append(df_antigo[(df_antigo['Texto'].str.contains('bolsonaro'))|
          (df_antigo['Texto'].str.contains('Bolsonaro'))|
          (df_antigo['Texto'].str.contains('BOLSONARO'))|
         (df_antigo['Texto'].str.contains('jair'))|
          (df_antigo['Texto'].str.contains('Jair'))|
          (df_antigo['Texto'].str.contains('JAIR'))|
         (df_antigo['Texto'].str.contains(' PL'))|
          (df_antigo['Texto'].str.contains('PL '))
         
         ])
df_bolsonaro = df_bolsonaro.drop_duplicates()
df_bolsonaro = df_bolsonaro.reset_index(drop=1)
df_bolsonaro

# df_train_bolsonaro = df_bolsonaro[df_bolsonaro['Eh_RT']=='N'].sample(frac = 0.2)
# df_train_bolsonaro.to_csv('classifica_bolsonaro.csv')
# df_train_bolsonaro

df_lula = pd.read_csv('extracoes/extracao_28_09_lula.csv', index_col=0)


df_lula = df_lula.append(df_antigo[(df_antigo['Texto'].str.contains('lula'))|
          (df_antigo['Texto'].str.contains('Lula'))|
          (df_antigo['Texto'].str.contains('LULA'))|
         (df_antigo['Texto'].str.contains('Inacio'))|
          (df_antigo['Texto'].str.contains('inacio'))|
          (df_antigo['Texto'].str.contains('lulinha'))|
         (df_antigo['Texto'].str.contains(' PT'))|
          (df_antigo['Texto'].str.contains('PT '))
         
         ])
df_lula = df_lula.drop_duplicates()

df_lula = df_lula.reset_index(drop=1)
df_lula

#df_train_lula = df_lula[df_lula['Eh_RT']=='N'].sample(frac = 0.2)
#df_train_lula.to_csv('classifica_lula.csv')
#df_train_lula

df_ciro = pd.read_csv('extracoes/extracao_28_09_ciro.csv', index_col=0)


df_ciro = df_ciro.append(df_antigo[(df_antigo['Texto'].str.contains('ciro'))|
          (df_antigo['Texto'].str.contains('Ciro'))|
          (df_antigo['Texto'].str.contains('CIRO'))|
         (df_antigo['Texto'].str.contains('pdt '))|
          (df_antigo['Texto'].str.contains(' pdt'))|
          (df_antigo['Texto'].str.contains('PDT '))|
         (df_antigo['Texto'].str.contains(' PDT'))
         
         ])
df_ciro = df_ciro.drop_duplicates()
df_ciro = df_ciro.reset_index(drop=1)

# df_train_ciro = df_ciro[df_ciro['Eh_RT']=='N'].sample(frac = 0.2)
# df_train_ciro.to_csv('classifica_ciro.csv')
# df_train_ciro

df_simone = pd.read_csv('extracoes/extracao_28_09_simone.csv', index_col=0)


df_simone = df_simone.append(df_antigo[(df_antigo['Texto'].str.contains('simone'))|
          (df_antigo['Texto'].str.contains('Simone'))|
          (df_antigo['Texto'].str.contains('SIMONE'))|
         (df_antigo['Texto'].str.contains('tebet'))|
          (df_antigo['Texto'].str.contains('Tebet'))|
          (df_antigo['Texto'].str.contains('TEBET'))|
         (df_antigo['Texto'].str.contains('MDB'))|
         (df_antigo['Texto'].str.contains('mdb'))
         
         ])
df_simone = df_simone.drop_duplicates()
df_simone = df_simone.reset_index(drop=1)
df_simone

# df_train_simone = df_simone[df_simone['Eh_RT']=='N'].sample(frac = 0.2)
# df_train_simone.to_csv('classifica_simone.csv')
# df_train_simone

def cleaning( review, remove_stopwords=True):
    words = review.lower().split()
    
    if remove_stopwords:
        stops = set(stopwords.words("portuguese")+
           ['em','sao','ao','de','da','do','para','c','co','kg','un','ml','pct','und','das','no','ou','pc','gr','pt','cm',
 'vd','com','sem','gfa','jg','la','1','2','3','4','5',
'6','7','8','9','0','a','b','c','d','e','lt','f','g',
'h','i','j','k','l','m','n','o','p','q','r','s','t',
'u','v','x','w','y','z','rt','RT','tô','tá','https','http','vc'])
        words = [w for w in words if not w in stops]

    #words = re.sub("[^a-zA-Z]"," ", words)
    b=[]
    stemmer = nltk.stem.RSLPStemmer()
    for word in words:
        b.append(''.join(c[0] for c in itertools.groupby(unidecode(stemmer.stem(word)))).replace('.', '').replace('_', ''))
    return(b)

def token_sem_stopwords(df):
    df['novo_texto'] = df['Texto']
    df['novo_texto'] = df['novo_texto'].str.replace('[,.:;!?]+', ' ', regex=True)
    df['novo_texto'] = df['novo_texto'].str.replace ('[/<>()|\+\-\=\$%&#*_@\'\"]+', ' ', regex=True)
    df['novo_texto'] = df['novo_texto'].str.replace('[0-9]+', '', regex=True)
    df['novo_texto'] = df['novo_texto'].apply(lambda x: cleaning(x))
    return df

df_bolsonaro = token_sem_stopwords(df_bolsonaro)
df_lula = token_sem_stopwords(df_lula)
df_simone = token_sem_stopwords(df_simone)
df_ciro = token_sem_stopwords(df_ciro)

df_bolsonaro.to_excel('Bolsonaro_todos_sem_stop.xlsx')
df_lula.to_excel('Lula_todos_sem_stop.xlsx')
df_simone.to_excel('Simone_todos_sem_stop.xlsx')
df_ciro.to_excel('Ciro_todos_sem_stop.xlsx')